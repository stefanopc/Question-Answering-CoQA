{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c0541c8-e108-4d46-872f-7fa02fb37f68",
      "metadata": {
        "id": "1c0541c8-e108-4d46-872f-7fa02fb37f68"
      },
      "source": [
        "# **Question Answering with Transformers on CoQA**\n",
        "\n",
        "### Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aWqZ1XYkUe4G",
      "metadata": {
        "id": "aWqZ1XYkUe4G"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.25.1\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "to4VXNG6kaQu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to4VXNG6kaQu",
        "outputId": "0ceb3a29-9b85-4bb4-a3e6-8628864bf06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "\n",
        "drive_path_model = '/content/gdrive/MyDrive/AssignmentNLP/'\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gqncYswiDQNh",
      "metadata": {
        "id": "gqncYswiDQNh"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import datasets\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from functools import partial\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from transformers import AutoTokenizer, EncoderDecoderModel, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "import torch\n",
        "\n",
        "!wget https://raw.githubusercontent.com/allenai/allennlp-models/main/allennlp_models/rc/tools/squad.py\n",
        "\n",
        "import squad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13CbdPf0DMuz",
      "metadata": {
        "id": "13CbdPf0DMuz"
      },
      "outputs": [],
      "source": [
        "def set_reproducibility(seed):\n",
        "    ''' Sets a given seed for reproducibility'''\n",
        "    \n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1MfwWi4jv6hj",
      "metadata": {
        "id": "1MfwWi4jv6hj"
      },
      "outputs": [],
      "source": [
        "# seeds: 42, 1337, 2022\n",
        "\n",
        "seed = 42\n",
        "set_reproducibility(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae86583-911b-4272-849c-4fde26fe0464",
      "metadata": {
        "id": "dae86583-911b-4272-849c-4fde26fe0464"
      },
      "source": [
        "### Downloading CoQA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54bcaf3a-677f-41e7-a7fb-2fe568edb208",
      "metadata": {
        "id": "54bcaf3a-677f-41e7-a7fb-2fe568edb208"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "988ecfeb-4e73-4719-974f-90e7311d1641",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "988ecfeb-4e73-4719-974f-90e7311d1641",
        "outputId": "f84cae98-ef03-4826-fbf4-b684720d32b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading CoQA train data split... (it may take a while)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "coqa-train-v1.0.json: 49.0MB [00:05, 8.23MB/s]                            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download completed!\n",
            "Downloading CoQA test data split... (it may take a while)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "coqa-dev-v1.0.json: 9.09MB [00:01, 7.25MB/s]                            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download completed!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aS6ZJ1xoNke3",
      "metadata": {
        "id": "aS6ZJ1xoNke3"
      },
      "outputs": [],
      "source": [
        "# JSON file paths\n",
        "train_file = 'coqa/train.json'\n",
        "test_file = 'coqa/test.json'\n",
        "\n",
        "# JSON files to Pandas Dataframe object\n",
        "coqa_train = pd.read_json(train_file)\n",
        "coqa_test = pd.read_json(test_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rf-L7rlAN3tB",
      "metadata": {
        "id": "rf-L7rlAN3tB"
      },
      "source": [
        "The following function allows to build the new dataframe with the useful features for question answering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HeUbYbH31E3N",
      "metadata": {
        "id": "HeUbYbH31E3N"
      },
      "outputs": [],
      "source": [
        "def build_dataframe(data):\n",
        "  '''\n",
        "  Builds the dataframe by creating one QA pair per row, each one with \n",
        "  its ID, source, story and rational\n",
        "\n",
        "  :param data: Pandas Dataframe object data \n",
        "\n",
        "  :return pd.DataFrame: the new built dataframe \n",
        "  '''\n",
        "\n",
        "  # drop irrelevant column\n",
        "  data = data.drop('version', axis=1)\n",
        "\n",
        "  cols = ['doc_id', 'source', 'story', 'question', 'answer', 'rational']\n",
        "  df_list = []\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    for i in range(len(row['data']['questions'])):\n",
        "        data_list = []\n",
        "        data_list.append(index+1)\n",
        "        data_list.append(row['data']['source'])\n",
        "\n",
        "        data_list.append(row['data']['story'].replace('\\n', '').strip())\n",
        "        data_list.append(row['data']['questions'][i]['input_text'])\n",
        "        data_list.append(row['data']['answers'][i]['input_text'])\n",
        "        data_list.append(row['data']['answers'][i]['span_text'])\n",
        "        \n",
        "        df_list.append(data_list)\n",
        "\n",
        "  return pd.DataFrame(df_list, columns=cols) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CgqdRjhcJAuj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgqdRjhcJAuj",
        "outputId": "ac768fb9-9e3e-4ad1-98aa-d6c1328d3d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: (108647, 6)\n",
            "Test set shape: (7983, 6)\n"
          ]
        }
      ],
      "source": [
        "# build dataframe for both train and test data\n",
        "df_train = build_dataframe(coqa_train)\n",
        "df_test = build_dataframe(coqa_test)\n",
        "\n",
        "print('Training set shape:', df_train.shape)\n",
        "print('Test set shape:', df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55iV8Mg7MXjE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "55iV8Mg7MXjE",
        "outputId": "068eaaf8-858b-47ed-8a29-015c45abbe6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45ab723d-473b-4faf-9f74-106bd288a9f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>rational</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>When was the Vat formally opened?</td>\n",
              "      <td>It was formally established in 1475</td>\n",
              "      <td>Formally established in 1475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what is the library for?</td>\n",
              "      <td>research</td>\n",
              "      <td>he Vatican Library is a research library</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>for what subjects?</td>\n",
              "      <td>history, and law</td>\n",
              "      <td>Vatican Library is a research library for hist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>and?</td>\n",
              "      <td>philosophy, science and theology</td>\n",
              "      <td>Vatican Library is a research library for hist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
              "      <td>what was started in 2014?</td>\n",
              "      <td>a  project</td>\n",
              "      <td>March 2014, the Vatican Library began an initi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108642</th>\n",
              "      <td>7199</td>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n",
              "      <td>Who was a sub?</td>\n",
              "      <td>Xabi Alonso</td>\n",
              "      <td>substitute Xabi Alonso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108643</th>\n",
              "      <td>7199</td>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n",
              "      <td>Was it his first game this year?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Xabi Alonso made his first appearance of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108644</th>\n",
              "      <td>7199</td>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n",
              "      <td>What position did the team reach?</td>\n",
              "      <td>third</td>\n",
              "      <td>Real moved up to third in the table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108645</th>\n",
              "      <td>7199</td>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n",
              "      <td>Who was ahead of them?</td>\n",
              "      <td>Barca.</td>\n",
              "      <td>six points behind Barca.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108646</th>\n",
              "      <td>7199</td>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Cristiano Ronaldo provided the perfec...</td>\n",
              "      <td>By how much?</td>\n",
              "      <td>six points</td>\n",
              "      <td>six points behind Barca.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108647 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45ab723d-473b-4faf-9f74-106bd288a9f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45ab723d-473b-4faf-9f74-106bd288a9f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45ab723d-473b-4faf-9f74-106bd288a9f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        doc_id     source                                              story  \\\n",
              "0            1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "1            1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "2            1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "3            1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "4            1  wikipedia  The Vatican Apostolic Library (), more commonl...   \n",
              "...        ...        ...                                                ...   \n",
              "108642    7199        cnn  (CNN) -- Cristiano Ronaldo provided the perfec...   \n",
              "108643    7199        cnn  (CNN) -- Cristiano Ronaldo provided the perfec...   \n",
              "108644    7199        cnn  (CNN) -- Cristiano Ronaldo provided the perfec...   \n",
              "108645    7199        cnn  (CNN) -- Cristiano Ronaldo provided the perfec...   \n",
              "108646    7199        cnn  (CNN) -- Cristiano Ronaldo provided the perfec...   \n",
              "\n",
              "                                 question  \\\n",
              "0       When was the Vat formally opened?   \n",
              "1                what is the library for?   \n",
              "2                      for what subjects?   \n",
              "3                                    and?   \n",
              "4               what was started in 2014?   \n",
              "...                                   ...   \n",
              "108642                     Who was a sub?   \n",
              "108643   Was it his first game this year?   \n",
              "108644  What position did the team reach?   \n",
              "108645             Who was ahead of them?   \n",
              "108646                       By how much?   \n",
              "\n",
              "                                     answer  \\\n",
              "0       It was formally established in 1475   \n",
              "1                                  research   \n",
              "2                          history, and law   \n",
              "3          philosophy, science and theology   \n",
              "4                                a  project   \n",
              "...                                     ...   \n",
              "108642                          Xabi Alonso   \n",
              "108643                                  Yes   \n",
              "108644                                third   \n",
              "108645                               Barca.   \n",
              "108646                           six points   \n",
              "\n",
              "                                                 rational  \n",
              "0                            Formally established in 1475  \n",
              "1                he Vatican Library is a research library  \n",
              "2       Vatican Library is a research library for hist...  \n",
              "3       Vatican Library is a research library for hist...  \n",
              "4       March 2014, the Vatican Library began an initi...  \n",
              "...                                                   ...  \n",
              "108642                             substitute Xabi Alonso  \n",
              "108643   Xabi Alonso made his first appearance of the ...  \n",
              "108644                Real moved up to third in the table  \n",
              "108645                          six points behind Barca.   \n",
              "108646                           six points behind Barca.  \n",
              "\n",
              "[108647 rows x 6 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OfB_DdzhWH3V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "OfB_DdzhWH3V",
        "outputId": "95eba9e2-f982-4303-ac52-a8336b8e6f11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4d7007ff-1c33-4d8e-88e2-4b0cb593bd66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>rational</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>What color was Cotton?</td>\n",
              "      <td>white</td>\n",
              "      <td>a little white kitten named Cotton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Where did she live?</td>\n",
              "      <td>in a barn</td>\n",
              "      <td>in a barn near a farm house, there lived a lit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Did she live alone?</td>\n",
              "      <td>no</td>\n",
              "      <td>Cotton wasn't alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Who did she live with?</td>\n",
              "      <td>with her mommy and 5 sisters</td>\n",
              "      <td>with her mommy and 5 other sisters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>What color were her sisters?</td>\n",
              "      <td>orange and white</td>\n",
              "      <td>her sisters were all orange with beautiful whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7978</th>\n",
              "      <td>500</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n",
              "      <td>where does the nickname \"Sin City\" come from?</td>\n",
              "      <td>The city's tolerance for numerous forms of adu...</td>\n",
              "      <td>The city's tolerance for numerous forms of adu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7979</th>\n",
              "      <td>500</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n",
              "      <td>Which state is it in?</td>\n",
              "      <td>Nevada</td>\n",
              "      <td>Vegas, is the 28th-most populated city in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7980</th>\n",
              "      <td>500</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n",
              "      <td>Is it located in a desert?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>within the greater Mojave Desert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7981</th>\n",
              "      <td>500</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n",
              "      <td>what is the name of the desert?</td>\n",
              "      <td>Mojave Desert.</td>\n",
              "      <td>Mojave Desert.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7982</th>\n",
              "      <td>500</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Las Vegas (, Spanish for \"The Meadows\"), offic...</td>\n",
              "      <td>is it a small city?</td>\n",
              "      <td>No</td>\n",
              "      <td>the most populated city in the state of Nevada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7983 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d7007ff-1c33-4d8e-88e2-4b0cb593bd66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d7007ff-1c33-4d8e-88e2-4b0cb593bd66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d7007ff-1c33-4d8e-88e2-4b0cb593bd66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      doc_id     source                                              story  \\\n",
              "0          1     mctest  Once upon a time, in a barn near a farm house,...   \n",
              "1          1     mctest  Once upon a time, in a barn near a farm house,...   \n",
              "2          1     mctest  Once upon a time, in a barn near a farm house,...   \n",
              "3          1     mctest  Once upon a time, in a barn near a farm house,...   \n",
              "4          1     mctest  Once upon a time, in a barn near a farm house,...   \n",
              "...      ...        ...                                                ...   \n",
              "7978     500  wikipedia  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
              "7979     500  wikipedia  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
              "7980     500  wikipedia  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
              "7981     500  wikipedia  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
              "7982     500  wikipedia  Las Vegas (, Spanish for \"The Meadows\"), offic...   \n",
              "\n",
              "                                           question  \\\n",
              "0                            What color was Cotton?   \n",
              "1                               Where did she live?   \n",
              "2                               Did she live alone?   \n",
              "3                            Who did she live with?   \n",
              "4                      What color were her sisters?   \n",
              "...                                             ...   \n",
              "7978  where does the nickname \"Sin City\" come from?   \n",
              "7979                          Which state is it in?   \n",
              "7980                     Is it located in a desert?   \n",
              "7981                what is the name of the desert?   \n",
              "7982                            is it a small city?   \n",
              "\n",
              "                                                 answer  \\\n",
              "0                                                 white   \n",
              "1                                             in a barn   \n",
              "2                                                    no   \n",
              "3                          with her mommy and 5 sisters   \n",
              "4                                      orange and white   \n",
              "...                                                 ...   \n",
              "7978  The city's tolerance for numerous forms of adu...   \n",
              "7979                                             Nevada   \n",
              "7980                                                Yes   \n",
              "7981                                     Mojave Desert.   \n",
              "7982                                                 No   \n",
              "\n",
              "                                               rational  \n",
              "0                    a little white kitten named Cotton  \n",
              "1     in a barn near a farm house, there lived a lit...  \n",
              "2                                   Cotton wasn't alone  \n",
              "3                    with her mommy and 5 other sisters  \n",
              "4     her sisters were all orange with beautiful whi...  \n",
              "...                                                 ...  \n",
              "7978  The city's tolerance for numerous forms of adu...  \n",
              "7979  Vegas, is the 28th-most populated city in the ...  \n",
              "7980                   within the greater Mojave Desert  \n",
              "7981                                     Mojave Desert.  \n",
              "7982     the most populated city in the state of Nevada  \n",
              "\n",
              "[7983 rows x 6 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6xJZmJU71PTu",
      "metadata": {
        "id": "6xJZmJU71PTu"
      },
      "source": [
        "### [Task 1] Remove unanswerable QA pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OcKUzUPRIXTe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcKUzUPRIXTe",
        "outputId": "6277e61d-39c4-46c1-a4ba-dcf16fd94f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of unanswerable questions in the training set is:  1371\n",
            "The number of unanswerable questions in the test set is:  66\n"
          ]
        }
      ],
      "source": [
        "# locate unanswerable QA pairs (i.e. answer is unknown)\n",
        "unanswerable_train = df_train.loc[df_train['answer'] == 'unknown'].index\n",
        "unanswerable_test = df_test.loc[df_test['answer'] == 'unknown'].index\n",
        "\n",
        "print('The number of unanswerable questions in the training set is: ', len(unanswerable_train))\n",
        "print('The number of unanswerable questions in the test set is: ', len(unanswerable_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "riQH9Qf0qkI9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riQH9Qf0qkI9",
        "outputId": "10993e18-54fc-4fb6-bec1-b9fecba8fde5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After removing the unanswerable QA pairs, the training set has a number of rows of 107276\n",
            "After removing the unanswerable QA pairs, the test set has a number of rows of 7917\n"
          ]
        }
      ],
      "source": [
        "# remove unanswerable QA pairs both on training and test data\n",
        "df_train.drop(unanswerable_train, inplace = True)\n",
        "df_test.drop(unanswerable_test, inplace = True)\n",
        "\n",
        "print(f'After removing the unanswerable QA pairs, the training set has a number of rows of {df_train.shape[0]}')\n",
        "print(f'After removing the unanswerable QA pairs, the test set has a number of rows of {df_test.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zt3X1IEJ3mq6",
      "metadata": {
        "id": "zt3X1IEJ3mq6"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AVmNjbS_l8XD",
      "metadata": {
        "id": "AVmNjbS_l8XD"
      },
      "source": [
        "We now explore a random example of a story, question and answer of the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ehbpCBTaGfPj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "ehbpCBTaGfPj",
        "outputId": "9d9b52d4-8795-4349-bf76-9445e1c13206"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jamie Oliver has been invited by Gordon Brown to prepare a banquet at No.10 for President Barack Obama and other leaders of the G20, offering a cut-price menu to reflect times when trade and industry are far from prosperous and the rate of employment is decreasing. Downing Street sources say Oliver, the well-known chef, will cook using \"honest high-street products\" and avoid expensive or \"fancy\" ingredients. The prime minister is trying to avoid a repeat of the embarrassment last year when he sat down to an 18-course banquet at a Japanese summit to discuss world food shortages. Obama, President Nicolas Sarkozy of France, Chancellor Angela Merkel of Germany and other leaders will be served by apprentices from Fifteen, the London restaurant Oliver founded to help train young people in poverty in order to make a living by mastering a skill. Brown wants the dinner to reflect the emphasis of the London summit, which he hopes will lead to an agreement to lift the world out of recession.\"To be invited to cook for such an important group of people, who are trying to solve some of the world\\'s major problems, is really a privilege,\" said Oliver. \"I\\'m hoping the menu I\\'m working on will show British food and produce is some of the best in the world, but also show we have pioneered a high-quality apprentice scheme at Fifteen London that is giving young people a skill to be proud of.\" The chef has not yet finalized me menu, but is expected to draw inspiration from his latest book, Jamie\\'s Ministry of Food, which has budget recipes for beef and ale stew and \"impressive\" chocolate fudge cake. ( )'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['story'][1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VOzY1DGsF_IJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VOzY1DGsF_IJ",
        "outputId": "b210170b-5908-47cf-f1e3-c604246a9687"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Who was the French president?'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['question'][1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x9fzwC7zGR3_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x9fzwC7zGR3_",
        "outputId": "d57ff0f4-36fc-46a8-c25e-648e8255919b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nicolas Sarkozy'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['answer'][1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PZZqnFV5mMOy",
      "metadata": {
        "id": "PZZqnFV5mMOy"
      },
      "source": [
        "Plotting the distribution of the different sources (wikipedia, cnn, gutenberg, race, mctest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zgHa899NkQwx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "zgHa899NkQwx",
        "outputId": "81d9a8c2-10f8-4c98-9e8e-7285fc091b13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='source', ylabel='count'>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='source', data=df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zqtqbSysF4rp",
      "metadata": {
        "id": "zqtqbSysF4rp"
      },
      "source": [
        "We will now plot the distribution of the story words in the training set and show itsnstatistics like count, mean, min, max values and 99% percentile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oYdn0vRKhjCH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "oYdn0vRKhjCH",
        "outputId": "5268e928-913a-44f6-816a-798361fdccff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_story_words = pd.DataFrame({'story_words': df_train['story'].str.split().apply(len)})\n",
        "\n",
        "sns.histplot(df_story_words, bins=150, kde=False)\n",
        "sns.set(rc={'figure.figsize':(6,4)})\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E7ZWgWVmbr2G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "E7ZWgWVmbr2G",
        "outputId": "3fc6b5bb-ae3b-45d8-8e7f-b770f99707c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-75f62927-e773-4090-a50d-102a1f92542e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>107276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>270.867594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>62.913194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>70.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>266.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99%</th>\n",
              "      <td>515.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75f62927-e773-4090-a50d-102a1f92542e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75f62927-e773-4090-a50d-102a1f92542e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75f62927-e773-4090-a50d-102a1f92542e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         story_words\n",
              "count  107276.000000\n",
              "mean      270.867594\n",
              "std        62.913194\n",
              "min        70.000000\n",
              "50%       266.000000\n",
              "99%       515.000000\n",
              "max      1030.000000"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_story_words.describe(percentiles=[.99])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c-KMfr3RHfdd",
      "metadata": {
        "id": "c-KMfr3RHfdd"
      },
      "source": [
        "The results show that the max length of the story in the training set is 1030, but the 99 percentile is 515.\n",
        "\n",
        "Now we will repeat the same process to analyze the statistics of the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mcduJvo_7ybb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "mcduJvo_7ybb",
        "outputId": "b234ddad-dd3f-4d96-b3b3-7773ca6adf96"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "question_words = df_train['question'].str.split().apply(len)\n",
        "df_question_words = pd.DataFrame({'question_words': question_words})\n",
        "\n",
        "sns.histplot(df_question_words, bins=int(question_words.max()), kde=False)\n",
        "sns.set(rc={'figure.figsize':(6,4)})\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hOeSSy_O8uQQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "hOeSSy_O8uQQ",
        "outputId": "e12c1b64-663d-45bc-87d4-388c381795d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6ad8018a-4b15-40e3-addd-fc5289dc2b61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>107276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.457511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.472835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99%</th>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ad8018a-4b15-40e3-addd-fc5289dc2b61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ad8018a-4b15-40e3-addd-fc5289dc2b61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ad8018a-4b15-40e3-addd-fc5289dc2b61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       question_words\n",
              "count   107276.000000\n",
              "mean         5.457511\n",
              "std          2.472835\n",
              "min          1.000000\n",
              "50%          5.000000\n",
              "99%         12.000000\n",
              "max         42.000000"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_question_words.describe(percentiles=[.99])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KT3qnPsoIv6e",
      "metadata": {
        "id": "KT3qnPsoIv6e"
      },
      "source": [
        "The plot and the statistical values of the answers above show that the max length is 42, while the 99 percentile is 12.\n",
        "\n",
        "The max input length of the encoder for the Bert model is 512, which is able to fit almost all the story and question's lengths. Therefore we set 512 as the input length for the models, as only a minimal part of the total dialogues would be truncated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vNNkQ0oXqK6l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vNNkQ0oXqK6l",
        "outputId": "b09de320-161c-4cd4-f94d-311cf30e1d3b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "answer_words = df_train['answer'].str.split().apply(len)\n",
        "df_answer_words = pd.DataFrame({'answer_words': answer_words})\n",
        "\n",
        "sns.histplot(df_answer_words, bins=int(answer_words.max()), kde=False)\n",
        "sns.set(rc={'figure.figsize':(6,4)})\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fCo2IUwQqSh4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "fCo2IUwQqSh4",
        "outputId": "ccbcdda4-3775-47ad-f109-a23685c3f179"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9327d2f7-656f-46c3-89e3-a648efecec35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>107276.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.675090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.929003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99%</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>353.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9327d2f7-656f-46c3-89e3-a648efecec35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9327d2f7-656f-46c3-89e3-a648efecec35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9327d2f7-656f-46c3-89e3-a648efecec35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        answer_words\n",
              "count  107276.000000\n",
              "mean        2.675090\n",
              "std         2.929003\n",
              "min         1.000000\n",
              "50%         2.000000\n",
              "99%        13.000000\n",
              "max       353.000000"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_answer_words.describe(percentiles=[.99])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hWNxPljZqz4L",
      "metadata": {
        "id": "hWNxPljZqz4L"
      },
      "source": [
        "Considering the 99 percentile of the answers, the max decoder length was set to 16."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2EkwnXyLXM9D",
      "metadata": {
        "id": "2EkwnXyLXM9D"
      },
      "source": [
        "We now define a function which adds dialogue history to each document in the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XWnBi9MISVJ1",
      "metadata": {
        "id": "XWnBi9MISVJ1"
      },
      "outputs": [],
      "source": [
        "def add_dialogue_history(df):\n",
        "    '''\n",
        "    Computes the dialogue history for each document in the DataFrame and appends it \n",
        "    to each row as a new column.\n",
        "\n",
        "    :param df: The DataFrame for which to compute the dialogue history\n",
        "\n",
        "    :return: A new DataFrame with the added dialogue history column\n",
        "    '''\n",
        "\n",
        "    # group the df by doc_id and extract the QA pairs for each group\n",
        "    doc_ids = df['doc_id'].unique()\n",
        "    dialogues = []\n",
        "\n",
        "    for id in doc_ids:\n",
        "        group = df.loc[df['doc_id'] == id]\n",
        "        dialogues.append(group[['question', 'answer']].to_numpy())\n",
        "\n",
        "    # list of dialogue histories\n",
        "    history_list = []\n",
        "    for dialogue in dialogues:\n",
        "        for i in range(len(dialogue)):\n",
        "            # append each dialogue up to each row\n",
        "            history_list.append(dialogue[:i])\n",
        "\n",
        "    # Create a copy of the original df and add the dialogue history as a new column\n",
        "    df_history = df.copy()\n",
        "    df_history['history'] = history_list\n",
        "\n",
        "    return df_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F9FIvukcyPpa",
      "metadata": {
        "id": "F9FIvukcyPpa"
      },
      "outputs": [],
      "source": [
        "# add history column to both training and test sets\n",
        "df_train = add_dialogue_history(df_train)\n",
        "df_test  = add_dialogue_history(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29-Fow7AyQ8U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "29-Fow7AyQ8U",
        "outputId": "0272aabf-d3b0-48a9-80bc-9f19db2b9539"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-956cc012-a754-42d6-ae17-8e467a5c1ecc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>rational</th>\n",
              "      <th>history</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>What color was Cotton?</td>\n",
              "      <td>white</td>\n",
              "      <td>a little white kitten named Cotton</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Where did she live?</td>\n",
              "      <td>in a barn</td>\n",
              "      <td>in a barn near a farm house, there lived a lit...</td>\n",
              "      <td>[[What color was Cotton?, white]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Did she live alone?</td>\n",
              "      <td>no</td>\n",
              "      <td>Cotton wasn't alone</td>\n",
              "      <td>[[What color was Cotton?, white], [Where did s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Who did she live with?</td>\n",
              "      <td>with her mommy and 5 sisters</td>\n",
              "      <td>with her mommy and 5 other sisters</td>\n",
              "      <td>[[What color was Cotton?, white], [Where did s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mctest</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>What color were her sisters?</td>\n",
              "      <td>orange and white</td>\n",
              "      <td>her sisters were all orange with beautiful whi...</td>\n",
              "      <td>[[What color was Cotton?, white], [Where did s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-956cc012-a754-42d6-ae17-8e467a5c1ecc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-956cc012-a754-42d6-ae17-8e467a5c1ecc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-956cc012-a754-42d6-ae17-8e467a5c1ecc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   doc_id  source                                              story  \\\n",
              "0       1  mctest  Once upon a time, in a barn near a farm house,...   \n",
              "1       1  mctest  Once upon a time, in a barn near a farm house,...   \n",
              "2       1  mctest  Once upon a time, in a barn near a farm house,...   \n",
              "3       1  mctest  Once upon a time, in a barn near a farm house,...   \n",
              "4       1  mctest  Once upon a time, in a barn near a farm house,...   \n",
              "\n",
              "                       question                        answer  \\\n",
              "0        What color was Cotton?                         white   \n",
              "1           Where did she live?                     in a barn   \n",
              "2           Did she live alone?                            no   \n",
              "3        Who did she live with?  with her mommy and 5 sisters   \n",
              "4  What color were her sisters?              orange and white   \n",
              "\n",
              "                                            rational  \\\n",
              "0                 a little white kitten named Cotton   \n",
              "1  in a barn near a farm house, there lived a lit...   \n",
              "2                                Cotton wasn't alone   \n",
              "3                 with her mommy and 5 other sisters   \n",
              "4  her sisters were all orange with beautiful whi...   \n",
              "\n",
              "                                             history  \n",
              "0                                                 []  \n",
              "1                  [[What color was Cotton?, white]]  \n",
              "2  [[What color was Cotton?, white], [Where did s...  \n",
              "3  [[What color was Cotton?, white], [Where did s...  \n",
              "4  [[What color was Cotton?, white], [Where did s...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mf_2MznugbNN",
      "metadata": {
        "id": "mf_2MznugbNN"
      },
      "source": [
        "### [Task 2] Train, Validation and Test splits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dpmosionnHY",
      "metadata": {
        "id": "2dpmosionnHY"
      },
      "source": [
        "We will split the dataset at dialogue level, in such a way that a dialogue appears in one split only. The split is performed in this way: the original training set is divided into training (80%) and validation (20%) sets, while the test set is the one which was previously defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uxtFAO9sPKWM",
      "metadata": {
        "id": "uxtFAO9sPKWM"
      },
      "outputs": [],
      "source": [
        "def train_validation_split(df, train_size):\n",
        "  '''\n",
        "  Splits a dataframe into training and validation set at dialogue level\n",
        "\n",
        "  :param df: Dataframe to split\n",
        "  :param train_size: Ratio of the dialogue in the training set\n",
        "\n",
        "  :return:\n",
        "    - split_df_train: Dataframe containing all the documents of the training set\n",
        "    - df_val : Dataframe containing all the documents of the validation set\n",
        "  '''\n",
        "  # get unique dialogues and shuffle them\n",
        "  dialogues = df['doc_id'].unique()\n",
        "  np.random.shuffle(dialogues)\n",
        "\n",
        "  # calculate the index where the split between training and val should occur\n",
        "  sep = int(train_size * len(dialogues))\n",
        "\n",
        "  # select the dialogues up to the sep index for training and val sets\n",
        "  train_dialogues, val_dialogues = dialogues[:sep], dialogues[sep:]\n",
        "\n",
        "  # select all rows from the input df that belong to the dialogues in the sets\n",
        "  df_train = df.loc[df['doc_id'].isin(train_dialogues)]\n",
        "  df_val = df.loc[df['doc_id'].isin(val_dialogues)]\n",
        "\n",
        "  return df_train, df_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AszzIzw04Zax",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AszzIzw04Zax",
        "outputId": "4caa5ee3-de84-4948-c8b8-6040175668d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape:  (85683, 7)\n",
            "Validation set shape:   (21593, 7)\n",
            "Test set shape:   (7917, 7)\n"
          ]
        }
      ],
      "source": [
        "df_train, df_val = train_validation_split(df_train, 0.8)\n",
        "\n",
        "print(\"Training set shape: \", df_train.shape)\n",
        "print(\"Validation set shape:  \", df_val.shape)\n",
        "print(\"Test set shape:  \", df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dy82h8A8B3Wp",
      "metadata": {
        "id": "dy82h8A8B3Wp"
      },
      "source": [
        "### [Task 3] Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v6AAcRlNJRQu",
      "metadata": {
        "id": "v6AAcRlNJRQu"
      },
      "source": [
        "Definition of two models:\n",
        "\n",
        "*   BERTTiny (bert-tiny)\n",
        "*   DistilRoBERTa (distilroberta-base)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2Aupwx-vB3B-",
      "metadata": {
        "id": "2Aupwx-vB3B-"
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "bert_tiny = 'prajjwal1/bert-tiny'\n",
        "distilroberta = 'distilroberta-base'\n",
        "\n",
        "# Max input tokens of the encoder\n",
        "ENCODER_MAX_LENGTH = 512\n",
        "\n",
        "# Max output tokens of the decoder\n",
        "DECODER_MAX_LENGTH = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uXbS4WYzOQ0S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "00c382897a2a4c3984b14567306bb924",
            "1dbc475b896e4a609934cad5dbed3d08",
            "a765e2c42a8843c7910a75595763ea29",
            "76207509b0ab41b9a8b3cae247065d80",
            "33d883bd5940441a9de0cce238bf446b",
            "5e3f39bb62c74302b19c4c0760deaab8",
            "67dd841ba86f4a97a10f0253687b1d74",
            "d676c5f4ab0d47359a8efeab5c0cc026",
            "7b3ac4d67de24b97aa2d39347f71412f",
            "8c769801b9294973a603db20e308b235",
            "336a96e4d95a4f30ada5ef06ffc4f849",
            "fcec5f44406b4cb6880161a44ec438ce",
            "f513bb11e90e4d899ecc0b56da3f78ee",
            "0b02bf5d846748598ef022963ca67b9c",
            "dda4decc9ea046d9901a3862b071ee41",
            "370257f905a04841863a5c52f8bde89a",
            "2e0260bfc4a54888b53bee0f7a786dfd",
            "7b56afc1aa634734909398f0d1ebbd1e",
            "863ffd5b4e1e4844b86ba7632414eacc",
            "b647f51bfbaa4dc29232e95a26c3b509",
            "6705d0c4f6f04c96b0352ab8a9bd799d",
            "3ab1af60ebc0412eab9776ab52383fb8",
            "66d5368fd5a1451bb1d4ed8e7e8e207a",
            "906e76d9755148efa9a42a3a2af9399a",
            "ba7c988d06864da78f4ec296e8edb284",
            "2e6df08878f34e92956338b187afedb7",
            "3df83a3154304de1aaa731aaff141be6",
            "2405d3c5acbd4c52a1cf9ac65dcc8dca",
            "6d765acf12a145f092c6cd31658855a4",
            "98e7f643b37d40429f78fbe06b857089",
            "f5dd871153644c09bd258667a552693a",
            "80183abab2d746f18c7c29810e3134f3",
            "81babf89a0ea4de696b3ec5a47ddd89f",
            "806cee3421144b139039e3fa4be51bee",
            "94fb1ed5ea8f4170a08ce53c2c392ee1",
            "c52684ddca504e6bacef326202a4c600",
            "5e11f4bab8c44e8da226c929035e44eb",
            "f8a163ca4ad74167b013b27d2d5dc340",
            "1856d7790da749ce8ead539aa8bb1a3f",
            "b729297bf100461ba39d660b1ab278eb",
            "7d287fb504bf4d3ba70c19a3383a46a9",
            "45d69abb80c3464e8ebbc36005b9a6dc",
            "fb314ed9c38c4ed8b2e3645c1803219d",
            "ca55023d93f840f68c1719cc0deb7e8f",
            "de8e4bc49cf34719bb905c30352b1bf6",
            "417fd532c18744279e495ef245c7f1d3",
            "fd2a000332c24f959079a28ba3914195",
            "02365d82a99b41069185495b7b3e29b5",
            "19f888eb45bb46db924ff279cae3cef8",
            "8a7c2ccaa29c4a06ab840bffc0ba2c85",
            "2f1cb741295a4a5bb7689c796bd91d16",
            "7bb345c3a264435b836ece9bc04eee63",
            "3948feb7087d4612aca8620bc0454039",
            "2be60df0375e4035bc7d84e79c6786d8",
            "41cc7814de824e64814f54959d80273b",
            "c4048089ad8648ffb8e09b200dc69fb2",
            "61343b9db4a94863a9fa47d882dfbda7",
            "cdc9015eddc646d7972d8fd0a84091b9",
            "13323ce56d5c4c89870fc29120dba7af",
            "d049febe793b41f08355bd5f2366d683",
            "1d1e18b6e3de474693c2383a22cc9bf2",
            "268caf42bfaf4897ac141eba1a77da1d",
            "318a9d233a3c49d2af3523f67b8c82f7",
            "763448388d4740f7b552f074d692a691",
            "5aa2a096d9814b5198788c4284df468f",
            "e4fc9aa9e2ac4216b857f1b249718ca4"
          ]
        },
        "id": "uXbS4WYzOQ0S",
        "outputId": "582ad4f7-666e-41e5-e6d0-6055ef6098c4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00c382897a2a4c3984b14567306bb924",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcec5f44406b4cb6880161a44ec438ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66d5368fd5a1451bb1d4ed8e7e8e207a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "806cee3421144b139039e3fa4be51bee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de8e4bc49cf34719bb905c30352b1bf6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4048089ad8648ffb8e09b200dc69fb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loading the tokenizers for the two models\n",
        "bert_tiny_tokenizer = AutoTokenizer.from_pretrained(bert_tiny)\n",
        "distilroberta_tokenizer = AutoTokenizer.from_pretrained(distilroberta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "odD8v9vLJtxR",
      "metadata": {
        "id": "odD8v9vLJtxR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DrIcaBRUB8Zb",
      "metadata": {
        "id": "DrIcaBRUB8Zb"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name, tokenizer):\n",
        "  '''\n",
        "  Loads an encoder-decoder pre-trained model and corresponding tokenizer\n",
        "\n",
        "  :param model_name: name of the model to load\n",
        "  :param tokenizer: the model tokenizer to load\n",
        "\n",
        "  :return:\n",
        "    model: pretrained encoder-decoder transformer model\n",
        "\n",
        "  '''\n",
        "  model = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, \n",
        "                                                              model_name).to(device) \n",
        "\n",
        "  model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "  model.config.eos_token_id = tokenizer.sep_token_id\n",
        "  model.config.pad_token_id = tokenizer.pad_token_id\n",
        "  model.config.max_new_tokens = DECODER_MAX_LENGTH\n",
        "  model.config.vocab_size = model.config.decoder.vocab_size\n",
        "  model.config.early_stopping = True\n",
        "  model.config.no_repeat_ngram_size = 3\n",
        "  model.config.num_beams = 4\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iuMBaiAYXw5g",
      "metadata": {
        "id": "iuMBaiAYXw5g"
      },
      "source": [
        "### [Task 4] Question generation with text passage $P$ and question $Q$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xoQr_KuQB-lw",
      "metadata": {
        "id": "xoQr_KuQB-lw"
      },
      "outputs": [],
      "source": [
        "def generate_answer(model, tokenizer, story, question):\n",
        "  '''\n",
        "  Generates an answer given a question and a story.\n",
        "\n",
        "  :param model: the model used to generate the answer\n",
        "  :param tokenizer: the tokenizer of the model\n",
        "  :param story: string representing the story of the question\n",
        "  :param question: string representing the question\n",
        "\n",
        "  :return:\n",
        "    - the generated answer\n",
        "\n",
        "  '''\n",
        "  # tokenize the input\n",
        "  inputs = tokenizer(question, story, padding=\"max_length\", truncation=\"only_second\",\n",
        "                     max_length=ENCODER_MAX_LENGTH)\n",
        "\n",
        "  # generate answer tokens through beam search\n",
        "  outputs = model.generate(input_ids=torch.as_tensor([inputs.input_ids]).to(device),\n",
        "                           attention_mask=torch.as_tensor([inputs.attention_mask]).to(device),\n",
        "                           max_length=DECODER_MAX_LENGTH)\n",
        "  \n",
        "  # decode the answer \n",
        "  generated = tokenizer.decode(outputs.tolist()[0], skip_special_tokens=True)\n",
        "  \n",
        "  return generated"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UP12NXbTX62_",
      "metadata": {
        "id": "UP12NXbTX62_"
      },
      "source": [
        "### [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bDRCr7wwCCMN",
      "metadata": {
        "id": "bDRCr7wwCCMN"
      },
      "outputs": [],
      "source": [
        "def generate_answer_with_history(model, tokenizer, story, question, history):\n",
        "  '''\n",
        "  Generates an answer given a story and question and \n",
        "  taking into account the QA history.\n",
        "\n",
        "  :param model: the model used to generate the answer\n",
        "  :param tokenizer: the tokenizer of the model\n",
        "  :param story: string representing the story of the question\n",
        "  :param question: string representing the question\n",
        "  :param history: list represening past questions and answers on the same story\n",
        "\n",
        "  :return:\n",
        "    - the generated answer\n",
        "\n",
        "  '''\n",
        "\n",
        "  # history string for QAs with SEP token\n",
        "  str_history = tokenizer.sep_token.join([f' {question} {tokenizer.sep_token} {answer} ' for question, answer in history])\n",
        "\n",
        "  # story and history tokenized                \n",
        "  inputs = tokenizer(question, f' {story} {tokenizer.sep_token} {str_history} ', padding=\"max_length\", truncation=\"only_second\", max_length=ENCODER_MAX_LENGTH)\n",
        "  \n",
        "  # generate answer tokens through beam search\n",
        "  outputs = model.generate(input_ids=torch.as_tensor([inputs.input_ids]).to(device),\n",
        "                           attention_mask=torch.as_tensor([inputs.attention_mask]).to(device),\n",
        "                           max_length=DECODER_MAX_LENGTH)\n",
        "   \n",
        "  # decode the answer \n",
        "  generated = tokenizer.decode(outputs.tolist()[0], skip_special_tokens=True)\n",
        "\n",
        "  return generated"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PdgwSKh3YMI_",
      "metadata": {
        "id": "PdgwSKh3YMI_"
      },
      "source": [
        "###[Task 6] Train and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hRe_wOsYCWlH",
      "metadata": {
        "id": "hRe_wOsYCWlH"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VWg_dQp9c1Bj",
      "metadata": {
        "id": "VWg_dQp9c1Bj"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sa0LgW2lCRm3",
      "metadata": {
        "id": "Sa0LgW2lCRm3"
      },
      "outputs": [],
      "source": [
        "def process_data_to_model_inputs(batch, tokenizer, hist = False):\n",
        "  '''\n",
        "  Tokenizes a batch of data\n",
        "\n",
        "  :param batch: the batch of data that will be tokenized\n",
        "  :param tokenizer: the model tokenizer that will be used to tokenize the batch\n",
        "  :param hist: a boolean to check if the QA history needs to be taken in account\n",
        "\n",
        "  :return batch: batch of data tokenized\n",
        "  '''\n",
        "\n",
        "  if hist:\n",
        "    # concatenate the strings in batch['story'] and batch['history']\n",
        "    story = [s + h for s, h in zip(batch['story'], batch['history'])]\n",
        "  else:\n",
        "    story = batch['story']\n",
        "\n",
        "  # the input is question + story (+ history)\n",
        "  inputs = tokenizer(batch['question'], story, padding=\"max_length\", truncation=\"only_second\", max_length=ENCODER_MAX_LENGTH)\n",
        "  \n",
        "  # the output is the answer\n",
        "  outputs = tokenizer(batch['answer'], padding=\"max_length\", truncation=True, max_length=DECODER_MAX_LENGTH)\n",
        "  \n",
        "  batch['input_ids'] = inputs.input_ids\n",
        "  batch['attention_mask'] = inputs.attention_mask\n",
        "  batch['labels'] = outputs.input_ids.copy()\n",
        "  \n",
        "  return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EFGm0WrCCYSB",
      "metadata": {
        "id": "EFGm0WrCCYSB"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(df, tokenizer, hist=False):\n",
        "    '''\n",
        "    Preprocesses the dataset by performing tokenization using the given tokenizer\n",
        "\n",
        "    param df: the input DataFrame to be tokenized\n",
        "    param tokenizer: the tokenizer to be used for tokenization\n",
        "    param hist: boolean to include QAs history in the input\n",
        "\n",
        "    :return df_tok: a tokenized dataset in the form of a `datasets.Dataset` object\n",
        "    '''\n",
        "    df_tok = df.copy()\n",
        "    \n",
        "    # convert the history column to a string\n",
        "    str_history = []\n",
        "    for history in df_tok['history']:\n",
        "        hist_string = tokenizer.sep_token.join([f' {question} {tokenizer.sep_token} {answer} ' for question, answer in history])\n",
        "        str_history.append(hist_string)\n",
        "\n",
        "    df_tok['history'] = str_history\n",
        "    \n",
        "    # convert the df to a HuggingFace dataset\n",
        "    df_tok = datasets.Dataset.from_pandas(df_tok)\n",
        "    \n",
        "    # tokenize the dataset\n",
        "    df_tok = df_tok.map(\n",
        "        process_data_to_model_inputs, \n",
        "        fn_kwargs={ \"tokenizer\": tokenizer, \"hist\" : hist},\n",
        "        batched=True, \n",
        "        batch_size=BATCH_SIZE,\n",
        "        remove_columns=list(df_train) + ['__index_level_0__'])\n",
        "\n",
        "    df_tok.set_format(type=\"torch\", device=device, columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "    return df_tok"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cde0ufZHCinF",
      "metadata": {
        "id": "Cde0ufZHCinF"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oCgYVO_TxsV2",
      "metadata": {
        "id": "oCgYVO_TxsV2"
      },
      "outputs": [],
      "source": [
        "# paths where models outputs are stored\n",
        "output_paths = ['output/bert_tiny_no_history',    \n",
        "                'output/bert_tiny_with_history',\n",
        "                'output/distilroberta_no_history', \n",
        "                'output/distilroberta_with_history']\n",
        "                \n",
        "output_paths = [drive_path_model + path for path in output_paths]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pCJmjsLzCcY9",
      "metadata": {
        "id": "pCJmjsLzCcY9"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred, tokenizer):\n",
        "    '''\n",
        "    Computes the F1 SQuAD score value for a batch of predictions.\n",
        "\n",
        "    :param pred: the predicted answers\n",
        "    :param tokenizer: the model tokenizer used to decode the predictions\n",
        "\n",
        "    :return a dictionary containing the computed f1 score for the entire batch \n",
        "    '''\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    f1_mean = []\n",
        "\n",
        "    for pred, label in zip(pred_str, label_str):\n",
        "        f1_mean.append(squad.compute_f1(pred, label))\n",
        "\n",
        "    return {\"average_f1_score\": np.mean(f1_mean)*100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DthRDrytbSut",
      "metadata": {
        "id": "DthRDrytbSut"
      },
      "outputs": [],
      "source": [
        "def train_model(model_name, tokenizer, output_path, history=False):\n",
        "    ''' \n",
        "    Defines Seq2Seq trainer for a model given its tokenizer\n",
        "    and saves the trained model.\n",
        "\n",
        "    :param model_name: the model to train\n",
        "    :param tokenizer: the model tokenizer\n",
        "    :param output_path: the path where the model will be saved\n",
        "    :param history: boolean to handle models with history\n",
        "    '''\n",
        "\n",
        "    # learning rates\n",
        "    if model_name == bert_tiny:\n",
        "      lr = 5e-4\n",
        "    elif model_name == distilroberta:\n",
        "       lr = 2e-5\n",
        "    \n",
        "    # Arguments for training the model\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        predict_with_generate=True,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        num_train_epochs=3,\n",
        "        weight_decay=0.01,\n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        fp16=True, \n",
        "        output_dir=output_path,\n",
        "        logging_steps=50,\n",
        "        optim='adamw_torch',\n",
        "        report_to='all'\n",
        "    )\n",
        "\n",
        "    # dataset tokenization\n",
        "    df_train_tokenized = preprocess_dataset(df_train, tokenizer, hist=history)\n",
        "    df_val_tokenized = preprocess_dataset(df_val, tokenizer, hist=history)\n",
        "\n",
        "    # load and configure model and tokenizer\n",
        "    model = load_model(model_name, tokenizer)\n",
        "\n",
        "    print(f'Model {model_name} downloaded running with seed {seed}')\n",
        "    \n",
        "    # define sequential trainer\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        compute_metrics=partial(compute_metrics, tokenizer=tokenizer),\n",
        "        tokenizer=tokenizer,\n",
        "        train_dataset=df_train_tokenized,\n",
        "        eval_dataset=df_val_tokenized,\n",
        "    )\n",
        "    trainer.train()\n",
        "    trainer.save_model(output_path+str(seed))\n",
        "        \n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A-8MZcmiCm6z",
      "metadata": {
        "id": "A-8MZcmiCm6z"
      },
      "source": [
        "**Bert Tiny without history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KyTQc7H77yr4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b3d4ea771b9340e0a4b40f07844650f8",
            "a315981fff494a13bb10b6579d5fed8a",
            "d4e8e1209d1c4913a38cdc48b2286386",
            "dd3d2d5154e44395bc9be985df228c6b",
            "3eee165d947d4db98ab1743f7753860a",
            "e1c73df4d04045e5becd90d2c1276a1e",
            "bcb3071df48f4977b0ffacade9deb29e",
            "5ecb3f4a204344c7a2a47a95260020ad",
            "a95f3ee6271147458f2b0e6e9652534b",
            "27cf7013141a471fbbf1370c4d838954",
            "0bb025db421a4c4eb5a4988c3f81e824",
            "47f0458513984df391e4b2bb8a522692",
            "2be8838046534f63a24d36961553d303",
            "e45ef3a4c49240c3ae71eb30f69c7259",
            "263e36380fd147368e0da6ed4bb4ea3f",
            "35b615799d2d4bfc9fdf2bedf2a7bfc8",
            "9cb6f5de97cb4405bd97df93b0991cdf",
            "f4d0eecdd09c480184d65d5f1df2b06f",
            "c59987184fae4ab1b0b884baba0c4f13",
            "ce7e97fce7e74114848471a39f004656",
            "209340095de64c3faeff65632f2e6e51",
            "3aaeb74f5566497dab1ad3fd645481c3",
            "61d2c015ac0c4847af369a6d4bf2dfa6",
            "c3ea6b0d0ad64e6f8631ab667806c6e9",
            "ff18c2b0d6e3496c94dc3906172ee1dd",
            "8f1ef483fa11465caea47f72309756fe",
            "5fdd7ed59ffd4bdfa6a6f351df651ff5",
            "139a25175e8248deabfcce578c89227a",
            "420d18720dda4a709039023df30a4be1",
            "d3fc77a171bc447e963400195782f7cc",
            "cc59c2e5bcb0412d8bf974576c245a5c",
            "d75defe59f5947eabc0b328476d12630",
            "53c100b5d2344df2b9112f4d6eb83ea6"
          ]
        },
        "id": "KyTQc7H77yr4",
        "outputId": "b7cbfd95-7ef6-45cb-8499-b8c683d3d3d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3d4ea771b9340e0a4b40f07844650f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/85683 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47f0458513984df391e4b2bb8a522692",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/21593 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61d2c015ac0c4847af369a6d4bf2dfa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prajjwal1/bert-tiny downloaded running with seed 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n",
            "***** Running training *****\n",
            "  Num examples = 85683\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8034\n",
            "  Number of trainable parameters = 8935997\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8034' max='8034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8034/8034 19:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Average F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.207500</td>\n",
              "      <td>1.158031</td>\n",
              "      <td>14.747457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.016300</td>\n",
              "      <td>1.114600</td>\n",
              "      <td>17.497087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.938700</td>\n",
              "      <td>1.117957</td>\n",
              "      <td>18.696648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-2678\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-2678/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-2678/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-2678/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-2678/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-5356\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-5356/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-5356/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-5356/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-5356/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-8034\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-8034/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-8034/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-8034/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history/checkpoint-8034/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history42\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history42/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history42/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history42/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_no_history42/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "train_model(bert_tiny, bert_tiny_tokenizer, output_paths[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kLAxF8h9C7Am",
      "metadata": {
        "id": "kLAxF8h9C7Am"
      },
      "source": [
        "**Bert Tiny with history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dq0sk8RyC5o-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2d6c8462e5194f47920c7fd6deacb792",
            "e610595e0a1143d9ba8b2ee9d832159d",
            "3a8e9ce6639641c1975b2520d5c6f55e",
            "14dbb12dfc1344099356823a94f5e234",
            "0ba25b7a74f046efa168a6d0d576630d",
            "00775a308b5945c38a5c60de18315a28",
            "05d21b03d0124dd1891ee6fb0f5fba84",
            "e55d12c597484326aadb57990c63db7b",
            "d54aee7c73a345d38708e57d4e712452",
            "252f34b9769244858b1ca8d84a1c64f8",
            "02fb4ae6a2b94b4db96cd6cd5961c5fe",
            "70763fc50a8e4749a1aacf9a2d3b5f18",
            "7933742965864f0dbb38474809965c54",
            "eea2bad6511244f1be19d7f1680a8283",
            "73be2f4ea675473b987d99eb85eb91b0",
            "d719dfa14fa14c6f8fcc7d99fc9bea85",
            "914f1ecd81354833b03936edff0d5571",
            "db22de02037d458eab75260a5ee4d8d9",
            "777b08740eb7448587ab7d6b2b569af9",
            "671c879dd63c4354875bedd134749a60",
            "43ea5bb871f24ffcad9c7b0b0c4f0525",
            "022423ae64cd4d16ac7f9d3ca0ff871b"
          ]
        },
        "id": "Dq0sk8RyC5o-",
        "outputId": "be00f103-d121-40bd-c1a6-452e8c089c21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d6c8462e5194f47920c7fd6deacb792",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/85683 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70763fc50a8e4749a1aacf9a2d3b5f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/21593 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--prajjwal1--bert-tiny/snapshots/6f75de8b60a9f8a2fdf7b69cbd86d9e64bcb3837/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--prajjwal1--bert-tiny/snapshots/6f75de8b60a9f8a2fdf7b69cbd86d9e64bcb3837/pytorch_model.bin\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at prajjwal1/bert-tiny.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--prajjwal1--bert-tiny/snapshots/6f75de8b60a9f8a2fdf7b69cbd86d9e64bcb3837/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"prajjwal1/bert-tiny\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Initializing prajjwal1/bert-tiny as a decoder model. Cross attention layers are added to prajjwal1/bert-tiny and randomly initialized if prajjwal1/bert-tiny's architecture allows for cross attention layers.\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--prajjwal1--bert-tiny/snapshots/6f75de8b60a9f8a2fdf7b69cbd86d9e64bcb3837/pytorch_model.bin\n",
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Set `config.is_decoder=True` and `config.add_cross_attention=True` for decoder_config\n",
            "Using cuda_amp half precision backend\n",
            "***** Running training *****\n",
            "  Num examples = 85683\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8034\n",
            "  Number of trainable parameters = 8935997\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prajjwal1/bert-tiny downloaded running with seed 42\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8034' max='8034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8034/8034 19:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Average F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.214600</td>\n",
              "      <td>1.167386</td>\n",
              "      <td>14.791757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.029200</td>\n",
              "      <td>1.121212</td>\n",
              "      <td>16.800013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.953500</td>\n",
              "      <td>1.123214</td>\n",
              "      <td>17.977760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-2678\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-2678/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-2678/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-2678/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-2678/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-5356\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-5356/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-5356/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-5356/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-5356/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-8034\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-8034/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-8034/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-8034/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history/checkpoint-8034/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history42\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history42/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history42/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history42/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/bert_tiny_with_history42/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "train_model(bert_tiny, bert_tiny_tokenizer, output_paths[1], history=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3_il-UMjFiRV",
      "metadata": {
        "id": "3_il-UMjFiRV"
      },
      "source": [
        "**Distilroberta without history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ohqfoS8-Dg1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7db2cf08c300424ba12669b17a452ffd",
            "e0e924de62164c5cb085de4fe33e72ca",
            "b8b6673c5b4c461a8704a71e93c0e8ce",
            "058b133994e54f339e1c802e4dbfce06",
            "9d7c8ec1978d4ac38efe6497b6ea7509",
            "7c3fa79cc3dd46718acd77e048f19cdf",
            "0caeace98ff74f1e8bdf2e7e21599960",
            "8aa15b79159c4cd28418b483817b6d4f",
            "341392a3bf2a40d89da24a9b10676990",
            "447a972b1f014467a22753bbfc224856",
            "d59d9b38875f4edba3a63696e3ef9b57",
            "003e1cb9be184da6a9ad92f007ff04b7",
            "87af19380b2a4702988be636853d10e8",
            "1cc7920636994ce5bd38059a38b34b72",
            "5d26e27079e54de186ff844d987ae169",
            "73ef928bd3bb4c358536f63905855af2",
            "70d9d21e8747457895b54da8f43881da",
            "615b36b5ebd5459ab956e7e0fd2ed12b",
            "71030d48f1074f0d89578b73c021ddb8",
            "6ee650b9726344f08f57caed8bd72305",
            "87ec4ad200aa4c7e99858d49b0c982e0",
            "e40c95c60b984067a03a4cf17f0dd377",
            "07371e3fd8b647549c987c2a6e0573b1",
            "7046ae3536c9463e834f0556c3309d1a",
            "526bb2ac9f20446ab2e9dcbb63c72c53",
            "8159a88d377b4cbb82d8f008b015a4ec",
            "e19368c7ea9f429a8aa8d25e61a01d99",
            "af6f51dc34d44a3f892bc0eeb4a41e1b",
            "445a21e01e4643e9995a4a8209c23d83",
            "20f3171b2fac497483488b2e812257c4",
            "f3d600d6338440109bade279a09c8413",
            "e87eeafb3ae14979bc57368677b8981a",
            "6d0ba307a1164a998b8feb4ddc4f756b"
          ]
        },
        "id": "ohqfoS8-Dg1e",
        "outputId": "5baef2fe-a801-45d3-b472-1ac669db7947"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7db2cf08c300424ba12669b17a452ffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/85683 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "003e1cb9be184da6a9ad92f007ff04b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/21593 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07371e3fd8b647549c987c2a6e0573b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model distilroberta-base downloaded running with seed 42\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n",
            "***** Running training *****\n",
            "  Num examples = 85683\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8034\n",
            "  Number of trainable parameters = 178476636\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5357' max='8034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5357/8034 1:26:31 < 43:15, 1.03 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Average F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.184900</td>\n",
              "      <td>1.105121</td>\n",
              "      <td>15.905614</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='87' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 87/675 02:30 < 17:06, 0.57 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-2678\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-2678/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-2678/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-2678/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-2678/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8034' max='8034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8034/8034 2:39:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Average F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.184900</td>\n",
              "      <td>1.105121</td>\n",
              "      <td>15.905614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.897082</td>\n",
              "      <td>30.652319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.857100</td>\n",
              "      <td>0.839871</td>\n",
              "      <td>35.538592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-5356\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-5356/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-5356/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-5356/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-5356/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-8034\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-8034/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-8034/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-8034/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history/checkpoint-8034/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history42\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history42/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history42/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history42/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_no_history42/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "train_model(distilroberta, distilroberta_tokenizer, output_paths[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-J4BpuM6FnJL",
      "metadata": {
        "id": "-J4BpuM6FnJL"
      },
      "source": [
        "**Distilroberta with history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NbUwxPSSDt-j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a93281e653db4f39b69d94ebf22ab5e2",
            "f5e01773652e4bfdb3be927117a04e4b",
            "543f88a07319477ab9d48db16ce6b325",
            "f42a787774424976992d55bcbbb76d0a",
            "e9aa01dfa6cb418f9bfd7370f196904f",
            "cb25aa6d6edc4397904f1ff5334250e9",
            "80652d62573146aaa81676197e0e111e",
            "88ba738e601d4fae81bf1fd2471f93e1",
            "c18782a84fe54b93952215d4d30a4d59",
            "aa29203f66314cccaff5cb0fe52cb4d4",
            "0857a0e1a3734382ab67ca7cdd5d4a09",
            "a06cd23e3e734d408943bcc561f17d99",
            "71852c5667a64d63b7f2d9ee497ad31c",
            "e4aa58cdcabe48d78fa7a61a7c85014d",
            "ea75041e5abd489bb2ee2ed323919098",
            "39c357ab6efa49c4a25c7225481c1b7c",
            "d13d6abac3904c8c9fdd2a1f6d977ce8",
            "91abe62cb4a44dd49b64a739944ac528",
            "c3ea2796b6154ba7b6035b069e435643",
            "d4469a2c9d2441e999fbfc754271406c",
            "8cc06ed1539a478eaa552bec03acf693",
            "ce2816521da64497b87b8d747115daf3",
            "18deb0f5f44b4b938b72cf4c75c75710",
            "4b8eb6e6aa9e4554bd326ee37a9c9b6b",
            "727a882084194eeb89f096b5eaf2484c",
            "f3043acf70e64865b73360a20115ee93",
            "aab87c62c29e4d2c93a699c1e1f895bc",
            "f92f4095ebf448dfabe16fe3c356398e",
            "aa89d897429c45b893128a1ddb8c59b2",
            "8b1f03ff0f5a49c6ab11a720ac78acf1",
            "ab3c81a5f167414b95e845b814973041",
            "7f96372af4834599b45ac9f6595a2e34",
            "03660b6798db4526921380fcf01e3b5f"
          ]
        },
        "id": "NbUwxPSSDt-j",
        "outputId": "ac0845c3-4050-4c30-91da-ffe3324975cc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a93281e653db4f39b69d94ebf22ab5e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/85683 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a06cd23e3e734d408943bcc561f17d99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/21593 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18deb0f5f44b4b938b72cf4c75c75710",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model distilroberta-base downloaded running with seed 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n",
            "***** Running training *****\n",
            "  Num examples = 85683\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8034\n",
            "  Number of trainable parameters = 178476636\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8034' max='8034' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8034/8034 2:42:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Average F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.178900</td>\n",
              "      <td>1.113288</td>\n",
              "      <td>15.678901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.935800</td>\n",
              "      <td>0.901456</td>\n",
              "      <td>30.009657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.851500</td>\n",
              "      <td>0.828706</td>\n",
              "      <td>36.599372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-2678\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-2678/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-2678/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-2678/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-2678/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-5356\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-5356/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-5356/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-5356/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-5356/special_tokens_map.json\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 21593\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-8034\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-8034/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-8034/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-8034/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history/checkpoint-8034/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history42\n",
            "Configuration saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history42/config.json\n",
            "Model weights saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history42/pytorch_model.bin\n",
            "tokenizer config file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history42/tokenizer_config.json\n",
            "Special tokens file saved in /content/gdrive/MyDrive/AssignmentNLP/output/distilroberta_with_history42/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "train_model(distilroberta, distilroberta_tokenizer, output_paths[3], history=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mwJBX37v5qMK",
      "metadata": {
        "id": "mwJBX37v5qMK"
      },
      "source": [
        "### Models evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L39ynJfReB28",
      "metadata": {
        "id": "L39ynJfReB28"
      },
      "outputs": [],
      "source": [
        "def compute_squad_f1_score(labels, predictions, tokenizer):\n",
        "  '''\n",
        "  Computes the F1 SQuAD score\n",
        "\n",
        "  :param labels: list containing the ground truth labels\n",
        "  :param predictions: list containing the predicted labels\n",
        "  :param tokenizer: model tokenizer\n",
        "\n",
        "  :return the mean of F1 SQuAD score for the entire input list\n",
        "  '''\n",
        "  label_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "  f1_mean = []\n",
        "\n",
        "  for pred, label in zip(predictions, label_str):\n",
        "    f1_mean.append(squad.compute_f1(pred, label))\n",
        "\n",
        "  return np.mean(f1_mean)*100,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WbmC7ZK2cxiq",
      "metadata": {
        "id": "WbmC7ZK2cxiq"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model_path, tokenizer, df_test_tok):\n",
        "  '''\n",
        "  Loads a model and evaluates it\n",
        "\n",
        "  :param model_path: path of the model to load\n",
        "  :param tokenizer: model tokenizer\n",
        "  :param df_test_tok: tokenized test set\n",
        "\n",
        "  :return test_set_score: F1 SQuAD score computed on the entire test set\n",
        "  '''\n",
        "  model = EncoderDecoderModel.from_pretrained(model_path).to(device) \n",
        "\n",
        "  def generate_predictions_eval(batch):\n",
        "    ''' Generates answer predictions for a batch of inputs for evaluation'''\n",
        "\n",
        "    outputs = model.generate(batch['input_ids'], \n",
        "                             attention_mask=batch['attention_mask'],\n",
        "                             max_new_tokens = DECODER_MAX_LENGTH)\n",
        "\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    batch[\"pred_answers\"] = output_str\n",
        "    return batch\n",
        "  \n",
        "  model_result = df_test_tok.map(generate_predictions_eval,\n",
        "                                 batched=True,\n",
        "                                 batch_size=BATCH_SIZE,\n",
        "                                 remove_columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "  # compute SQuAD f1 score on test set\n",
        "  test_set_score = compute_squad_f1_score(model_result['labels'], model_result['pred_answers'], tokenizer)  \n",
        "\n",
        "  return test_set_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h4_Wxr6bsFfM",
      "metadata": {
        "id": "h4_Wxr6bsFfM"
      },
      "outputs": [],
      "source": [
        "# evaluation on seeds: 42, 1337, 2022\n",
        "seeds = [42, 1337, 2022]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tq__PfuXaxnR",
      "metadata": {
        "id": "Tq__PfuXaxnR"
      },
      "source": [
        "Computing the averaged SQUAD F1-score obtained by bert-tiny and distil-roberta (both with and without history) on the test set and for all the given seeds (42, 1337 and 2022)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NDVEYOJK5wCo",
      "metadata": {
        "id": "NDVEYOJK5wCo"
      },
      "source": [
        "### Bert Tiny evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AXT1MSeQ5ybS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "d14ee9472f1246de87a35cf7b5979b16",
            "527fde93bb834d398782193a4c82f606",
            "596a5f25f611450fb82254a1293e8d53",
            "fd729b847a334e3fbe335a04f0a13549",
            "a4a6b74d9a7947c3a0da0cdeaa78df6f",
            "8b785be3be0a4637bedd46b859ef9308",
            "a511e276e7874e2aaaf7c8ac2e1bce0d",
            "f0d66f3d5c9d45a098973d5e95809b69",
            "f54f1dd0d6c84c01b6282c27ea970a8d",
            "23477dda7a5c4b42a7a22ac784a6d3a6",
            "b212a00677ee46cfa9cea22ce9564e16",
            "3b2d9bd552a14422a9800f8bcd63a255",
            "e85d25db049748c39da3ccfa859cdf2e",
            "567919b8e6ec4fe5965edc8603204312",
            "2c47bf9e79074855bfd7755e6a03c63b",
            "a84e287813684fe28cdf461f2b85845a",
            "fe860e20f8f94bd2802bbd677b47cfb1",
            "44778302e7c04bf88181f85b4e77c6ea",
            "77f75a713f4e481285a285a429974753",
            "fcd81bfab0624cde9695acee39edfd60",
            "3c2a2f2622ab40ed95e34354aae5b2b7",
            "fc1a407402454c0ea97375bbae0930da",
            "4f5095b17aee4ab9aba5479290af54ea",
            "9761ab80fab7495cb1841e901026229d",
            "4e964b93ca6747b5b7558cbcfc5309e4",
            "742fd41e9cf04473a7f5283a456182d3",
            "5fa4510aaff6433ea0e4fb0784a6f8d9",
            "8c1a3d7c10894b149e65a53e7f15ebda",
            "3a4e4041cedf4d649dbc4e1d9eff289c",
            "034a4424c7d34495ae7d08de59790a56",
            "2966dd5cf4e84a92995f7ec9c1799fe0",
            "04952950468741c38c3f660430e027e9",
            "8030d96bd2314964aa49f5add04bf522",
            "06193ad5aaf841e2b5296bf648681fd9",
            "441853a87c23448eac90173d7754c22e",
            "acb616c0df5445a2b965049e07990245",
            "e059f0ccf7e54dcc99a618da2fc19ef6",
            "ce59f4e42a35439e95a262fb0ca84306",
            "1933c4fb4d8847ba8843ec163293c5c6",
            "d0156be4e7f74b94a92d6caf325831cf",
            "0c69764bb0a8491194e810e5fb0d22dd",
            "76391e0c731b49aea065988f03e5a6d3",
            "13eae1ccd77d4d3cb0b5abcf09c059ca",
            "a0d529acb8b54faf8b2aa4dc4a659d96",
            "edf44220b4ea4e64a952063b7038846a",
            "170a8ce370de4197a62187f4847bd550",
            "34499c3002474437828722e5a55c981b",
            "9bc6dd8f7f274df9875adf75f1b89a1c",
            "6e31f89a37d6416fba93c9515c306f4b",
            "d9a6a9b2149840e895dca2b14370e632",
            "d7cf03b2e87f46c490f6a8939c317f58",
            "2a3f4ea3048b4cd2ad17ce7fae8ca320",
            "b945eff402b54ecbb0bdfcbe47b999e0",
            "d47ed74f44c44b11976240e1904fe575",
            "9227596bf39e47a3a5fc182bc9e0e51c",
            "24bbcc46ace74ed2926a94744ae94924",
            "eb43b3daf3d84169afa23bd2b9518412",
            "a63e618bfdda47308c76b7f91eb2751f",
            "635a90ca689141c799f067c57ecc58aa",
            "a7da45656fae40a2b7c54395cf036420",
            "ec923fa0d14343ebbaccd059c2e02b1b",
            "c8c7971ab98d4005af9494c5d8b60709",
            "16f444b1cb7d4cc69caff5305d03858f",
            "eb25b3f836e241c992758c2202c2cfda",
            "e2c83b0ad4fc46c9ba5b0863fc5bc503",
            "b85267bf54da4e60be3bb108b4c48a71",
            "d970ba8195c543ee83f4b38aa714275b",
            "76217cd68a824f8fb4e9c95b36d5564e",
            "7652d63d002944fd9f331db40de6e5f9",
            "9441a8eef9c4498eb78f52975a784d85",
            "ab7d0aebc1dc4ae28c69f07120642a1c",
            "a918a8238cd5406e8fdc11de9e801433",
            "943470c38ffe4134999c291739beadd0",
            "d937a092dc9d4eef83b92f98fcb00362",
            "03074449d9d1470abc0e7326b76a3519",
            "1aa2a348901649118779fd9799663f18",
            "37443e650a524060a6ecf4163565660d",
            "a80ef15d8e5543fcab39f8f2e63977cb",
            "b1d6fe6cfeae4a3cb9def3fd8f7e5353",
            "02390d5c8cc74acc8bc058cb3af7e260",
            "4ddfd91b158f4da88b72904c84f85b40",
            "3dbd1f4141a94abda79ef711e8648a97",
            "f9655150703a4f15ada6b3becca66a0d",
            "0ad5e0d105bc4efa998d585a2d94cc00",
            "b0f71d5dc1154c8e850265663df85c05",
            "17eae21975814d45bc1c8769cfbfc149",
            "d1aa1cc328ad496f8a4ace744d762d23",
            "e41ee42df821467495db78279dfa6d31"
          ]
        },
        "id": "AXT1MSeQ5ybS",
        "outputId": "9b2cebdc-bec8-42cc-fe1c-c38ab4732efb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d14ee9472f1246de87a35cf7b5979b16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b2d9bd552a14422a9800f8bcd63a255",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f5095b17aee4ab9aba5479290af54ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06193ad5aaf841e2b5296bf648681fd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edf44220b4ea4e64a952063b7038846a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24bbcc46ace74ed2926a94744ae94924",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d970ba8195c543ee83f4b38aa714275b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a80ef15d8e5543fcab39f8f2e63977cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average SQUAD F1 score of bert-tiny without history: 18.11\n",
            "Average SQUAD F1 score of bert-tiny with history: 17.71\n"
          ]
        }
      ],
      "source": [
        "# test set tokenization\n",
        "df_test_tok_no_history = preprocess_dataset(df_test, bert_tiny_tokenizer, hist = False)\n",
        "df_test_tok_with_history = preprocess_dataset(df_test, bert_tiny_tokenizer, hist = True)\n",
        "\n",
        "bert_tiny_f1_nohist, bert_tiny_f1_whist = [], []\n",
        "\n",
        "for seed in seeds:\n",
        "  # bert-tiny with no history\n",
        "  model_path_no_history = output_paths[0] + str(seed)\n",
        "  bert_tiny_f1_nohist.append(evaluate_model(model_path_no_history, bert_tiny_tokenizer, df_test_tok_no_history))\n",
        "\n",
        "  # bert-tiny with history\n",
        "  model_path_with_history = output_paths[1] + str(seed)\n",
        "  bert_tiny_f1_whist.append(evaluate_model(model_path_with_history, bert_tiny_tokenizer, df_test_tok_with_history))\n",
        "\n",
        "print(f'\\nAverage SQUAD F1 score of bert-tiny without history: {round(np.mean(bert_tiny_f1_nohist), 2)}')\n",
        "print(f'Average SQUAD F1 score of bert-tiny with history: {round(np.mean(bert_tiny_f1_whist), 2)}') "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pl8LeuQf51V6",
      "metadata": {
        "id": "pl8LeuQf51V6"
      },
      "source": [
        "### DistilRoberta evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AKtLT-cx529R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "c1c8d2c138324d8d8ab6dc950f5eba8c",
            "8e41bf37b23a4780961d7d418389412f",
            "463caaf4256f4618b1fdaf493dab04e0",
            "fa3a7ad946f14d12bb834f5aabb811ff",
            "b9aa5f0a1dcc4bcca75cf849d7741ac7",
            "c3560691cb354ec0843b42d8c7116920",
            "4a042b2190c2427eb8e9ef895c7307df",
            "c4d32493bb3440ba8a49b867a127d178",
            "0b5dd7d35f1545fc826f1bafdbf3a32a",
            "667f6193e27d453da789faaef54a9e06",
            "f044840136b24898b22ad877c31dc59f",
            "4d21ecd720c84a5f92307f65ee90b9da",
            "43c43acbb80447d697900e1824025974",
            "c6d22990841041e2b6de8a08eee2caeb",
            "04bbff0d71294b5cbf1dd0ff99fe2cb4",
            "6d81f694552c47a19d975f1377a8eac5",
            "6867503618aa4fe094de9f54bc1a1e61",
            "fe3606c8fddb45c993fe84860aee2e7b",
            "d80d7a75037d4266ab1696c28e29a887",
            "de4d7ec0e8294259b480971c03932315",
            "9897d3b4ff6140f1b8caef447d2429c0",
            "f8dad0829dbc426c878b9bb4e8eff76e",
            "ac072534f64141879541cf93a2cd2a81",
            "2a5c8ace4888437793b4084f1794d9c0",
            "185d57d17a094b69b10af2100249527e",
            "730229e78d1040ce8f27e10d8dee5805",
            "6376d27591524cc3bd97dc10474b53c1",
            "06aab251ba7c4435a0e154ccbf719e46",
            "43dbd6651a454ca19002218f5b7b558a",
            "a45851718c6a4c97886aea81dd674eb2",
            "cb496a31c3554e87990863c34b7a46d3",
            "187dd436f5dc4612b35fbe5e7ca1d44f",
            "5688647f5edd42d1b412b60295fe0d58",
            "8eeb6643953c4346945ee0c31e05515a",
            "70300bc467514072b5f3cc8fec05d5a0",
            "cb5cb3cfb2154df0b3427611a93b300a",
            "1ceba2d6eedd4abab4c07500379ddc71",
            "5877830c3f664cf88cebea033f0def8f",
            "2ef4e3468b9143aeb9504fb368f6eb3c",
            "7bd2ee1a04a84a0faa4e3af96ec9af8d",
            "222a2e222f9e4e4faa07dd59e4e981d3",
            "9b36cccd555145849c77ac92b49277f2",
            "67e324e806344852a04594e782e04e01",
            "4f4b44dc22284fb9901cc965554db85f",
            "a44d66a228aa42109e963edb9f0ceedb",
            "4e53070ea6b94117a43a8ec2bac124a1",
            "4c5a891cda844363846908aaf9e6ac63",
            "b808b31eb60e42919ce286eeac6070e2",
            "a2b3a05e042644379439188f5e2edc3d",
            "f62875e4db1f4b3a853a3c21c82b1789",
            "a38b2c65697a4bf39518004d5a3737b4",
            "6572774cc52042b79ec01eb26820a2c9",
            "899cc22c0f474872a035941ed9839a72",
            "da0b9a5af347464a8e2426bb287c82ac",
            "26c3224dfdad41538d00368841fda923",
            "43aac41a28cd49f48b7a88fc478e5652",
            "e4a495a424aa4959be5170255b4e2b4c",
            "806da89ef69846e29d73bd435263d92d",
            "7eadfb151f8b4cb7af3821c41498a197",
            "32cc04bfe8c54fc39f5bb7423a086317",
            "a8c23d583db44f3dad801a8dbc3fbd9b",
            "e47ac31583884f66bc4456774a81291a",
            "7ea0f3fd5df64f58897e0737126281a5",
            "4366352bb5564ecca0853fb8c877452f",
            "80b069c05257418b9ed486bb9f5944c3",
            "6a7c549d54864c39b197906900dca8c0",
            "91064ba04ca842239891b151e66ba2f7",
            "950501fab4d04343a16b24382703f1f2",
            "37cc1fd626ec41299ea5b06ac94bef8f",
            "6d1d638a0ead456cbac029b3dfa91b16",
            "670e1f0a09e8426995430c080a326bd7",
            "a5107458b71d49088ac8ba1804fc77e5",
            "6f88a19174e346ada4608be00173d038",
            "08734229160a42f890645ed3e67d48a5",
            "23cec81b6658401eb073279c911215a7",
            "853f64322bf2459ca83727e928cd8cdb",
            "b11de119eea743aab8b1cb83c2c9f944",
            "bec7051f3551487f9641a2e0c30c89df",
            "0c7039eeae394d718735567d8fdd2a30",
            "af3365892b0e49a9b4785259b45b920c",
            "352abfe283e4465fab1ac69c53f12af9",
            "71985a5bb3d245c38cc3d4e565956b34",
            "06594a961a894fba9fc3ff38007594f5",
            "2b8a592a688a4dbd8facd49ae67b28a1",
            "57fafb631fd64a2cb2d80e7a8579a49f",
            "c9d1433e897742b295ad3266681f7b0b",
            "9a156cd4f91347a2a9cd0f5eeecdb098",
            "848a1b35b45e49ba9d6e0f5816d856ce"
          ]
        },
        "id": "AKtLT-cx529R",
        "outputId": "6cd9e5c5-1256-429e-c802-16c685ac2b22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1c8d2c138324d8d8ab6dc950f5eba8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d21ecd720c84a5f92307f65ee90b9da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac072534f64141879541cf93a2cd2a81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eeb6643953c4346945ee0c31e05515a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a44d66a228aa42109e963edb9f0ceedb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43aac41a28cd49f48b7a88fc478e5652",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91064ba04ca842239891b151e66ba2f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bec7051f3551487f9641a2e0c30c89df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7917 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average SQUAD F1 score of distilroberta without history: 36.65\n",
            "Average SQUAD F1 score of distilroberta with history: 35.53\n"
          ]
        }
      ],
      "source": [
        "# test set tokenization\n",
        "df_test_tok_no_history = preprocess_dataset(df_test, distilroberta_tokenizer, hist = False)\n",
        "df_test_tok_with_history = preprocess_dataset(df_test, distilroberta_tokenizer, hist = True)\n",
        "\n",
        "distilroberta_f1_nohist, distilroberta_f1_whist = [], []\n",
        "\n",
        "for seed in seeds:\n",
        "  # distilroberta with no history\n",
        "  model_path_no_history = output_paths[2] + str(seed)\n",
        "  distilroberta_f1_nohist.append(evaluate_model(model_path_no_history, distilroberta_tokenizer, df_test_tok_no_history))\n",
        "\n",
        "  # distilroberta with history\n",
        "  model_path_with_history = output_paths[2] + str(seed)\n",
        "  distilroberta_f1_whist.append(evaluate_model(model_path_with_history, distilroberta_tokenizer, df_test_tok_with_history))\n",
        "\n",
        "print(f'\\nAverage SQUAD F1 score of distilroberta without history: {round(np.mean(distilroberta_f1_nohist), 2)}')\n",
        "print(f'Average SQUAD F1 score of distilroberta with history: {round(np.mean(distilroberta_f1_whist), 2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uk0ykH8O56O6",
      "metadata": {
        "id": "Uk0ykH8O56O6"
      },
      "source": [
        "### [Task 7] Error Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RsIK0K1pctvq",
      "metadata": {
        "id": "RsIK0K1pctvq"
      },
      "source": [
        "We will now compute and display the 5 worst answers predicted by both models for all the five possible sources: cnn, gutenberg, mctest, race, wikipedia, for which the answers have a SQuAD F1 score of 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lirU3Op9qqes",
      "metadata": {
        "id": "lirU3Op9qqes"
      },
      "outputs": [],
      "source": [
        "# sources: cnn, gutenberg, mctest, race, wikipedia\n",
        "sources = df_test['source'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8jOZxUO3D2HH",
      "metadata": {
        "id": "8jOZxUO3D2HH"
      },
      "outputs": [],
      "source": [
        "def compute_and_display_worst(model, tokenizer, df_pred, hist=False):\n",
        "    '''\n",
        "    Compute and display the five worst predictions for each source of a given model\n",
        "\n",
        "    :param model: the model used for the prediction\n",
        "    :param tokenizer: the model tokenizer\n",
        "    :param df: the dataframe containing the QA pairs\n",
        "    :param hist: a boolean for hadnling history\n",
        "    '''\n",
        "\n",
        "    # generate answer based on whether history is used or not\n",
        "    def generate_answer_func(x):\n",
        "        if hist:\n",
        "            return generate_answer_with_history(model, tokenizer, x['story'], x['question'], x['history'])\n",
        "        else:\n",
        "            return generate_answer(model, tokenizer, x['story'], x['question'])\n",
        "    \n",
        "    # apply generate_answer_func to each row to get predicted answer\n",
        "    df_pred['pred_answer'] = df_pred.apply(generate_answer_func, axis=1)\n",
        "\n",
        "    # compute F1 score for each QA pair\n",
        "    df_pred['SQUAD_F1'] = df_pred.apply(lambda row: squad.compute_f1(row['pred_answer'], row['answer']) * 100, axis=1)\n",
        "\n",
        "    df_grouped = df_pred.groupby('source')\n",
        "    df_worst = pd.DataFrame()\n",
        "\n",
        "    # get the worst 5 QA pairs for each source\n",
        "    for source in sources:\n",
        "      df_source = df_grouped.get_group(source)\n",
        "      df_worst_source = df_source.sort_values(by='SQUAD_F1').head(5)\n",
        "      df_worst_source['source'] = source\n",
        "      df_worst = pd.concat([df_worst, df_worst_source])\n",
        "\n",
        "    display(df_worst[['source', 'story','question', 'answer', 'pred_answer', 'SQUAD_F1']])\n",
        "\n",
        "    # clear GPU memory\n",
        "    del model\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OK53rx1F6Iaa",
      "metadata": {
        "id": "OK53rx1F6Iaa"
      },
      "source": [
        "### Bert-tiny without history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IcLX_QMwUdKv",
      "metadata": {
        "id": "IcLX_QMwUdKv"
      },
      "outputs": [],
      "source": [
        "# bert tiny without history\n",
        "model = EncoderDecoderModel.from_pretrained(output_paths[0] + str(seed)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aCcTHxUAIIr2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aCcTHxUAIIr2",
        "outputId": "fdfebcc4-8b33-4191-e779-ac1ab8940133"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0adf6c06-5fb7-43be-8a7a-a816341405b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>pred_answer</th>\n",
              "      <th>SQUAD_F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>mctest</td>\n",
              "      <td>There is a large tree in a park where all the ...</td>\n",
              "      <td>Does the tree house still exist?</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4967</th>\n",
              "      <td>mctest</td>\n",
              "      <td>Scott Alan woke up very early that morning in ...</td>\n",
              "      <td>What did the animal start doing?</td>\n",
              "      <td>barking</td>\n",
              "      <td>a dog</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4966</th>\n",
              "      <td>mctest</td>\n",
              "      <td>Scott Alan woke up very early that morning in ...</td>\n",
              "      <td>what was it near?</td>\n",
              "      <td>the river</td>\n",
              "      <td>the lake</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4964</th>\n",
              "      <td>mctest</td>\n",
              "      <td>Scott Alan woke up very early that morning in ...</td>\n",
              "      <td>what did scott want to do after he ate?</td>\n",
              "      <td>ride his bicycle</td>\n",
              "      <td>went to play</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4963</th>\n",
              "      <td>mctest</td>\n",
              "      <td>Scott Alan woke up very early that morning in ...</td>\n",
              "      <td>How old was the child for most of his adventures?</td>\n",
              "      <td>12</td>\n",
              "      <td>three</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>race</td>\n",
              "      <td>My doorbell rings. On the step, I find the eld...</td>\n",
              "      <td>Who is at the door?</td>\n",
              "      <td>An elderly Chinese lady and a little boy</td>\n",
              "      <td>her mother</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5692</th>\n",
              "      <td>race</td>\n",
              "      <td>A new study suggests that early exposure to ge...</td>\n",
              "      <td>Early exposure to what makes a stronger adult ...</td>\n",
              "      <td>germs</td>\n",
              "      <td>a heart attack</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5691</th>\n",
              "      <td>race</td>\n",
              "      <td>A new study suggests that early exposure to ge...</td>\n",
              "      <td>At what school?</td>\n",
              "      <td>Harvard Medical School</td>\n",
              "      <td>university of california</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5690</th>\n",
              "      <td>race</td>\n",
              "      <td>A new study suggests that early exposure to ge...</td>\n",
              "      <td>From where?</td>\n",
              "      <td>Boston</td>\n",
              "      <td>massachusetts</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5689</th>\n",
              "      <td>race</td>\n",
              "      <td>A new study suggests that early exposure to ge...</td>\n",
              "      <td>Who led the study?</td>\n",
              "      <td>Richard Blumberg</td>\n",
              "      <td>a professor</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>cnn</td>\n",
              "      <td>Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...</td>\n",
              "      <td>What does John Howard think of Abbott?</td>\n",
              "      <td>understood that you could make a new friend wi...</td>\n",
              "      <td>it's the most populous country.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4289</th>\n",
              "      <td>cnn</td>\n",
              "      <td>Tehran, Iran (CNN) -- A nuclear scientist was ...</td>\n",
              "      <td>what kind of vehicle exploded?</td>\n",
              "      <td>Peugeot 405</td>\n",
              "      <td>a bomb</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7012</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- President Barack Obama has nominated ...</td>\n",
              "      <td>And?</td>\n",
              "      <td>And the extent to which they cause civilian ca...</td>\n",
              "      <td>the u. s. army</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4287</th>\n",
              "      <td>cnn</td>\n",
              "      <td>Tehran, Iran (CNN) -- A nuclear scientist was ...</td>\n",
              "      <td>where did this take place?</td>\n",
              "      <td>Tehran</td>\n",
              "      <td>saudi arabia</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4286</th>\n",
              "      <td>cnn</td>\n",
              "      <td>Tehran, Iran (CNN) -- A nuclear scientist was ...</td>\n",
              "      <td>what was his name?</td>\n",
              "      <td>Reza Qashqaei</td>\n",
              "      <td>al - shabababa</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Staten Island is one of the five boroughs of N...</td>\n",
              "      <td>How many burroughs are there?</td>\n",
              "      <td>five</td>\n",
              "      <td>three</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4762</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Tuscany is a region in central Italy with an a...</td>\n",
              "      <td>What alcohol is made there?</td>\n",
              "      <td>Wine.</td>\n",
              "      <td>alcohol</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4761</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Tuscany is a region in central Italy with an a...</td>\n",
              "      <td>Was Florence ranked higher or lower?</td>\n",
              "      <td>Higher</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4760</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Tuscany is a region in central Italy with an a...</td>\n",
              "      <td>Which city had the second most tourists in the...</td>\n",
              "      <td>Pisa</td>\n",
              "      <td>rome</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4759</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Tuscany is a region in central Italy with an a...</td>\n",
              "      <td>When was it designated that?</td>\n",
              "      <td>1996.</td>\n",
              "      <td>1992</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XXII Northward, along the leeward coas...</td>\n",
              "      <td>What worked her way northward?</td>\n",
              "      <td>The _Ariel_</td>\n",
              "      <td>the ocean</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4520</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XIII. ST. VALENTINE'S DAY Miss Mohun c...</td>\n",
              "      <td>After how long?</td>\n",
              "      <td>after a long day</td>\n",
              "      <td>two days</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4519</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XIII. ST. VALENTINE'S DAY Miss Mohun c...</td>\n",
              "      <td>Who returned after dark?</td>\n",
              "      <td>Miss Mohun</td>\n",
              "      <td>her husband</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4518</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XIII. ST. VALENTINE'S DAY Miss Mohun c...</td>\n",
              "      <td>He returned after dark?</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4502</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XI Peter Rabbit and Jerry Muskrat Are ...</td>\n",
              "      <td>Why?</td>\n",
              "      <td>There won't be any room</td>\n",
              "      <td>because he didn't have to go to the house.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0adf6c06-5fb7-43be-8a7a-a816341405b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0adf6c06-5fb7-43be-8a7a-a816341405b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0adf6c06-5fb7-43be-8a7a-a816341405b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         source                                              story  \\\n",
              "4197     mctest  There is a large tree in a park where all the ...   \n",
              "4967     mctest  Scott Alan woke up very early that morning in ...   \n",
              "4966     mctest  Scott Alan woke up very early that morning in ...   \n",
              "4964     mctest  Scott Alan woke up very early that morning in ...   \n",
              "4963     mctest  Scott Alan woke up very early that morning in ...   \n",
              "23         race  My doorbell rings. On the step, I find the eld...   \n",
              "5692       race  A new study suggests that early exposure to ge...   \n",
              "5691       race  A new study suggests that early exposure to ge...   \n",
              "5690       race  A new study suggests that early exposure to ge...   \n",
              "5689       race  A new study suggests that early exposure to ge...   \n",
              "4140        cnn  Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...   \n",
              "4289        cnn  Tehran, Iran (CNN) -- A nuclear scientist was ...   \n",
              "7012        cnn  (CNN) -- President Barack Obama has nominated ...   \n",
              "4287        cnn  Tehran, Iran (CNN) -- A nuclear scientist was ...   \n",
              "4286        cnn  Tehran, Iran (CNN) -- A nuclear scientist was ...   \n",
              "76    wikipedia  Staten Island is one of the five boroughs of N...   \n",
              "4762  wikipedia  Tuscany is a region in central Italy with an a...   \n",
              "4761  wikipedia  Tuscany is a region in central Italy with an a...   \n",
              "4760  wikipedia  Tuscany is a region in central Italy with an a...   \n",
              "4759  wikipedia  Tuscany is a region in central Italy with an a...   \n",
              "210   gutenberg  CHAPTER XXII Northward, along the leeward coas...   \n",
              "4520  gutenberg  CHAPTER XIII. ST. VALENTINE'S DAY Miss Mohun c...   \n",
              "4519  gutenberg  CHAPTER XIII. ST. VALENTINE'S DAY Miss Mohun c...   \n",
              "4518  gutenberg  CHAPTER XIII. ST. VALENTINE'S DAY Miss Mohun c...   \n",
              "4502  gutenberg  CHAPTER XI Peter Rabbit and Jerry Muskrat Are ...   \n",
              "\n",
              "                                               question  \\\n",
              "4197                   Does the tree house still exist?   \n",
              "4967                   What did the animal start doing?   \n",
              "4966                                  what was it near?   \n",
              "4964            what did scott want to do after he ate?   \n",
              "4963  How old was the child for most of his adventures?   \n",
              "23                                  Who is at the door?   \n",
              "5692  Early exposure to what makes a stronger adult ...   \n",
              "5691                                    At what school?   \n",
              "5690                                        From where?   \n",
              "5689                                 Who led the study?   \n",
              "4140             What does John Howard think of Abbott?   \n",
              "4289                     what kind of vehicle exploded?   \n",
              "7012                                               And?   \n",
              "4287                         where did this take place?   \n",
              "4286                                 what was his name?   \n",
              "76                        How many burroughs are there?   \n",
              "4762                        What alcohol is made there?   \n",
              "4761               Was Florence ranked higher or lower?   \n",
              "4760  Which city had the second most tourists in the...   \n",
              "4759                       When was it designated that?   \n",
              "210                      What worked her way northward?   \n",
              "4520                                    After how long?   \n",
              "4519                           Who returned after dark?   \n",
              "4518                            He returned after dark?   \n",
              "4502                                               Why?   \n",
              "\n",
              "                                                 answer  \\\n",
              "4197                                                yes   \n",
              "4967                                            barking   \n",
              "4966                                          the river   \n",
              "4964                                   ride his bicycle   \n",
              "4963                                                 12   \n",
              "23             An elderly Chinese lady and a little boy   \n",
              "5692                                              germs   \n",
              "5691                             Harvard Medical School   \n",
              "5690                                             Boston   \n",
              "5689                                   Richard Blumberg   \n",
              "4140  understood that you could make a new friend wi...   \n",
              "4289                                        Peugeot 405   \n",
              "7012  And the extent to which they cause civilian ca...   \n",
              "4287                                             Tehran   \n",
              "4286                                      Reza Qashqaei   \n",
              "76                                                 five   \n",
              "4762                                              Wine.   \n",
              "4761                                             Higher   \n",
              "4760                                               Pisa   \n",
              "4759                                              1996.   \n",
              "210                                         The _Ariel_   \n",
              "4520                                   after a long day   \n",
              "4519                                         Miss Mohun   \n",
              "4518                                                yes   \n",
              "4502                            There won't be any room   \n",
              "\n",
              "                                     pred_answer  SQUAD_F1  \n",
              "4197                                          no       0.0  \n",
              "4967                                       a dog       0.0  \n",
              "4966                                    the lake       0.0  \n",
              "4964                                went to play       0.0  \n",
              "4963                                       three       0.0  \n",
              "23                                    her mother       0.0  \n",
              "5692                              a heart attack       0.0  \n",
              "5691                    university of california       0.0  \n",
              "5690                               massachusetts       0.0  \n",
              "5689                                 a professor       0.0  \n",
              "4140             it's the most populous country.       0.0  \n",
              "4289                                      a bomb       0.0  \n",
              "7012                              the u. s. army       0.0  \n",
              "4287                                saudi arabia       0.0  \n",
              "4286                              al - shabababa       0.0  \n",
              "76                                         three       0.0  \n",
              "4762                                     alcohol       0.0  \n",
              "4761                                          no       0.0  \n",
              "4760                                        rome       0.0  \n",
              "4759                                        1992       0.0  \n",
              "210                                    the ocean       0.0  \n",
              "4520                                    two days       0.0  \n",
              "4519                                 her husband       0.0  \n",
              "4518                                          no       0.0  \n",
              "4502  because he didn't have to go to the house.       0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "compute_and_display_worst(model, bert_tiny_tokenizer, df_test.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MfjZRjK26Mfd",
      "metadata": {
        "id": "MfjZRjK26Mfd"
      },
      "source": [
        "### Bert-tiny with history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aKnbF16h6Bpi",
      "metadata": {
        "id": "aKnbF16h6Bpi"
      },
      "outputs": [],
      "source": [
        "# bert tiny with history\n",
        "model = EncoderDecoderModel.from_pretrained(output_paths[1] + str(seed)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "huC_npYjW2CK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "huC_npYjW2CK",
        "outputId": "dfb9f13a-761f-42fc-e054-94f5eb8a7b23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-58bcfe05-4288-4190-a35a-8ade9521107c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>pred_answer</th>\n",
              "      <th>SQUAD_F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>mctest</td>\n",
              "      <td>There is a large tree in a park where all the ...</td>\n",
              "      <td>Does the tree house still exist?</td>\n",
              "      <td>yes</td>\n",
              "      <td>1876</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5088</th>\n",
              "      <td>mctest</td>\n",
              "      <td>The Rover family goes to the park for a wonder...</td>\n",
              "      <td>Will they bring their playmates?</td>\n",
              "      <td>they might</td>\n",
              "      <td>the park</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087</th>\n",
              "      <td>mctest</td>\n",
              "      <td>The Rover family goes to the park for a wonder...</td>\n",
              "      <td>Where will they visit next time?</td>\n",
              "      <td>the beach</td>\n",
              "      <td>paul</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5086</th>\n",
              "      <td>mctest</td>\n",
              "      <td>The Rover family goes to the park for a wonder...</td>\n",
              "      <td>Who else was there?</td>\n",
              "      <td>the Fidos</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5084</th>\n",
              "      <td>mctest</td>\n",
              "      <td>The Rover family goes to the park for a wonder...</td>\n",
              "      <td>Do they throw a ball around?</td>\n",
              "      <td>no</td>\n",
              "      <td>the park</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>race</td>\n",
              "      <td>My doorbell rings. On the step, I find the eld...</td>\n",
              "      <td>Who is at the door?</td>\n",
              "      <td>An elderly Chinese lady and a little boy</td>\n",
              "      <td>her mother</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5884</th>\n",
              "      <td>race</td>\n",
              "      <td>My name is James Brown. I have an 8-year-old d...</td>\n",
              "      <td>last name ?</td>\n",
              "      <td>Brown</td>\n",
              "      <td>mary.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5883</th>\n",
              "      <td>race</td>\n",
              "      <td>My name is James Brown. I have an 8-year-old d...</td>\n",
              "      <td>who is the author ?</td>\n",
              "      <td>James</td>\n",
              "      <td>mary.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5820</th>\n",
              "      <td>race</td>\n",
              "      <td>When I was young, I went looking for gold in C...</td>\n",
              "      <td>In the morning?</td>\n",
              "      <td>no</td>\n",
              "      <td>friday</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819</th>\n",
              "      <td>race</td>\n",
              "      <td>When I was young, I went looking for gold in C...</td>\n",
              "      <td>When would she be returning?</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>in the afternoon</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>cnn</td>\n",
              "      <td>Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...</td>\n",
              "      <td>What does John Howard think of Abbott?</td>\n",
              "      <td>understood that you could make a new friend wi...</td>\n",
              "      <td>it's the most important part of the country</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5156</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- For the first time since the massacre...</td>\n",
              "      <td>Does anything startle him?</td>\n",
              "      <td>yes</td>\n",
              "      <td>they were cousins</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5155</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- For the first time since the massacre...</td>\n",
              "      <td>What does Richie have difficulty doing?</td>\n",
              "      <td>sleeping</td>\n",
              "      <td>false</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5154</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- For the first time since the massacre...</td>\n",
              "      <td>True or False: That day will be the first time...</td>\n",
              "      <td>true</td>\n",
              "      <td>thursday</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5153</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- For the first time since the massacre...</td>\n",
              "      <td>When?</td>\n",
              "      <td>on Thursday</td>\n",
              "      <td>sleeping</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Staten Island is one of the five boroughs of N...</td>\n",
              "      <td>How many burroughs are there?</td>\n",
              "      <td>five</td>\n",
              "      <td>three</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5282</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Toronto is the most populous city in Canada an...</td>\n",
              "      <td>what part?</td>\n",
              "      <td>Ontario</td>\n",
              "      <td>new york</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5281</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Toronto is the most populous city in Canada an...</td>\n",
              "      <td>where is Toronto located?</td>\n",
              "      <td>Canada</td>\n",
              "      <td>new york</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5148</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Plymouth (i/ˈplɪməθ/) is a city on the south c...</td>\n",
              "      <td>What kind of exports came from Plymouth?</td>\n",
              "      <td>local minerals</td>\n",
              "      <td>two</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5147</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Plymouth (i/ˈplɪməθ/) is a city on the south c...</td>\n",
              "      <td>How many miles is it west-south-west of London?</td>\n",
              "      <td>190</td>\n",
              "      <td>the united kingdom</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XXII Northward, along the leeward coas...</td>\n",
              "      <td>What worked her way northward?</td>\n",
              "      <td>The _Ariel_</td>\n",
              "      <td>\" the island \"</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4721</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER VII The Beginning of Troubles Lily, as...</td>\n",
              "      <td>Did Liliy's man do as instructed?</td>\n",
              "      <td>yes</td>\n",
              "      <td>he was a nurse</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4720</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER VII The Beginning of Troubles Lily, as...</td>\n",
              "      <td>how?</td>\n",
              "      <td>cousin</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4719</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER VII The Beginning of Troubles Lily, as...</td>\n",
              "      <td>Was bernard's partner related to him?</td>\n",
              "      <td>yes</td>\n",
              "      <td>his mother</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4718</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER VII The Beginning of Troubles Lily, as...</td>\n",
              "      <td>what relation to him was Bernard's love?</td>\n",
              "      <td>doubting</td>\n",
              "      <td>go to the house</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58bcfe05-4288-4190-a35a-8ade9521107c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58bcfe05-4288-4190-a35a-8ade9521107c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58bcfe05-4288-4190-a35a-8ade9521107c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         source                                              story  \\\n",
              "4197     mctest  There is a large tree in a park where all the ...   \n",
              "5088     mctest  The Rover family goes to the park for a wonder...   \n",
              "5087     mctest  The Rover family goes to the park for a wonder...   \n",
              "5086     mctest  The Rover family goes to the park for a wonder...   \n",
              "5084     mctest  The Rover family goes to the park for a wonder...   \n",
              "23         race  My doorbell rings. On the step, I find the eld...   \n",
              "5884       race  My name is James Brown. I have an 8-year-old d...   \n",
              "5883       race  My name is James Brown. I have an 8-year-old d...   \n",
              "5820       race  When I was young, I went looking for gold in C...   \n",
              "5819       race  When I was young, I went looking for gold in C...   \n",
              "4140        cnn  Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...   \n",
              "5156        cnn  (CNN) -- For the first time since the massacre...   \n",
              "5155        cnn  (CNN) -- For the first time since the massacre...   \n",
              "5154        cnn  (CNN) -- For the first time since the massacre...   \n",
              "5153        cnn  (CNN) -- For the first time since the massacre...   \n",
              "76    wikipedia  Staten Island is one of the five boroughs of N...   \n",
              "5282  wikipedia  Toronto is the most populous city in Canada an...   \n",
              "5281  wikipedia  Toronto is the most populous city in Canada an...   \n",
              "5148  wikipedia  Plymouth (i/ˈplɪməθ/) is a city on the south c...   \n",
              "5147  wikipedia  Plymouth (i/ˈplɪməθ/) is a city on the south c...   \n",
              "210   gutenberg  CHAPTER XXII Northward, along the leeward coas...   \n",
              "4721  gutenberg  CHAPTER VII The Beginning of Troubles Lily, as...   \n",
              "4720  gutenberg  CHAPTER VII The Beginning of Troubles Lily, as...   \n",
              "4719  gutenberg  CHAPTER VII The Beginning of Troubles Lily, as...   \n",
              "4718  gutenberg  CHAPTER VII The Beginning of Troubles Lily, as...   \n",
              "\n",
              "                                               question  \\\n",
              "4197                   Does the tree house still exist?   \n",
              "5088                   Will they bring their playmates?   \n",
              "5087                   Where will they visit next time?   \n",
              "5086                                Who else was there?   \n",
              "5084                       Do they throw a ball around?   \n",
              "23                                  Who is at the door?   \n",
              "5884                                        last name ?   \n",
              "5883                                who is the author ?   \n",
              "5820                                    In the morning?   \n",
              "5819                       When would she be returning?   \n",
              "4140             What does John Howard think of Abbott?   \n",
              "5156                         Does anything startle him?   \n",
              "5155            What does Richie have difficulty doing?   \n",
              "5154  True or False: That day will be the first time...   \n",
              "5153                                              When?   \n",
              "76                        How many burroughs are there?   \n",
              "5282                                         what part?   \n",
              "5281                          where is Toronto located?   \n",
              "5148           What kind of exports came from Plymouth?   \n",
              "5147    How many miles is it west-south-west of London?   \n",
              "210                      What worked her way northward?   \n",
              "4721                  Did Liliy's man do as instructed?   \n",
              "4720                                               how?   \n",
              "4719              Was bernard's partner related to him?   \n",
              "4718           what relation to him was Bernard's love?   \n",
              "\n",
              "                                                 answer  \\\n",
              "4197                                                yes   \n",
              "5088                                         they might   \n",
              "5087                                          the beach   \n",
              "5086                                          the Fidos   \n",
              "5084                                                 no   \n",
              "23             An elderly Chinese lady and a little boy   \n",
              "5884                                              Brown   \n",
              "5883                                              James   \n",
              "5820                                                 no   \n",
              "5819                                           Saturday   \n",
              "4140  understood that you could make a new friend wi...   \n",
              "5156                                                yes   \n",
              "5155                                           sleeping   \n",
              "5154                                               true   \n",
              "5153                                        on Thursday   \n",
              "76                                                 five   \n",
              "5282                                            Ontario   \n",
              "5281                                             Canada   \n",
              "5148                                     local minerals   \n",
              "5147                                                190   \n",
              "210                                         The _Ariel_   \n",
              "4721                                                yes   \n",
              "4720                                             cousin   \n",
              "4719                                                yes   \n",
              "4718                                           doubting   \n",
              "\n",
              "                                      pred_answer  SQUAD_F1  \n",
              "4197                                         1876       0.0  \n",
              "5088                                     the park       0.0  \n",
              "5087                                         paul       0.0  \n",
              "5086                                           no       0.0  \n",
              "5084                                     the park       0.0  \n",
              "23                                     her mother       0.0  \n",
              "5884                                        mary.       0.0  \n",
              "5883                                        mary.       0.0  \n",
              "5820                                       friday       0.0  \n",
              "5819                             in the afternoon       0.0  \n",
              "4140  it's the most important part of the country       0.0  \n",
              "5156                            they were cousins       0.0  \n",
              "5155                                        false       0.0  \n",
              "5154                                     thursday       0.0  \n",
              "5153                                     sleeping       0.0  \n",
              "76                                          three       0.0  \n",
              "5282                                     new york       0.0  \n",
              "5281                                     new york       0.0  \n",
              "5148                                          two       0.0  \n",
              "5147                           the united kingdom       0.0  \n",
              "210                                \" the island \"       0.0  \n",
              "4721                               he was a nurse       0.0  \n",
              "4720                                          yes       0.0  \n",
              "4719                                   his mother       0.0  \n",
              "4718                              go to the house       0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "compute_and_display_worst(model, bert_tiny_tokenizer, df_test.copy(), hist = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-liuk2zM6QjW",
      "metadata": {
        "id": "-liuk2zM6QjW"
      },
      "source": [
        "### DistilRoBERTa without history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JOQfSF-o6QBH",
      "metadata": {
        "id": "JOQfSF-o6QBH"
      },
      "outputs": [],
      "source": [
        "# distilroberta without history\n",
        "model = EncoderDecoderModel.from_pretrained(output_paths[2] + str(seed)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MhGOJAGKW70M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "MhGOJAGKW70M",
        "outputId": "3e35e18d-5c47-4789-9a2c-dc1cb463f1eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-16de5dd8-a719-40e4-af29-e7cb464314dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>pred_answer</th>\n",
              "      <th>SQUAD_F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7931</th>\n",
              "      <td>mctest</td>\n",
              "      <td>The kitchen comes alive at night in the Sander...</td>\n",
              "      <td>What do they all do when the kids come in?</td>\n",
              "      <td>they all hide</td>\n",
              "      <td>go to the park</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4025</th>\n",
              "      <td>mctest</td>\n",
              "      <td>One morning, Justin woke up very excited. He w...</td>\n",
              "      <td>did he go to sleep sad?</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6653</th>\n",
              "      <td>mctest</td>\n",
              "      <td>A man sailed out to sea in a small boat. The s...</td>\n",
              "      <td>Did he fish for a long time?</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6652</th>\n",
              "      <td>mctest</td>\n",
              "      <td>A man sailed out to sea in a small boat. The s...</td>\n",
              "      <td>Did he get a bite?</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4029</th>\n",
              "      <td>mctest</td>\n",
              "      <td>John was in the third grade, and nine years ol...</td>\n",
              "      <td>Did he tell on them?</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>race</td>\n",
              "      <td>My doorbell rings. On the step, I find the eld...</td>\n",
              "      <td>Who is at the door?</td>\n",
              "      <td>An elderly Chinese lady and a little boy</td>\n",
              "      <td>her daughter</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5897</th>\n",
              "      <td>race</td>\n",
              "      <td>My name is James Brown. I have an 8-year-old d...</td>\n",
              "      <td>how old is the girl ?</td>\n",
              "      <td>17</td>\n",
              "      <td>Eight</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3165</th>\n",
              "      <td>race</td>\n",
              "      <td>\"Everything happens for the best,\" my mother s...</td>\n",
              "      <td>What did the father say?</td>\n",
              "      <td>Montgomery Ward wanted a sports-man</td>\n",
              "      <td>\"I don't want to play football.\"</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5896</th>\n",
              "      <td>race</td>\n",
              "      <td>My name is James Brown. I have an 8-year-old d...</td>\n",
              "      <td>and her dads ?</td>\n",
              "      <td>Bomba</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3167</th>\n",
              "      <td>race</td>\n",
              "      <td>\"Everything happens for the best,\" my mother s...</td>\n",
              "      <td>Did he get the job?</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>cnn</td>\n",
              "      <td>Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...</td>\n",
              "      <td>What does John Howard think of Abbott?</td>\n",
              "      <td>understood that you could make a new friend wi...</td>\n",
              "      <td>he's a pro-socialist</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3036</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Justin Bieber's newest friend is Mala...</td>\n",
              "      <td>How old is she?</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3037</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Justin Bieber's newest friend is Mala...</td>\n",
              "      <td>Why did they attack her?</td>\n",
              "      <td>outspoken support for girls' education</td>\n",
              "      <td>She was assassinated</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3038</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- Justin Bieber's newest friend is Mala...</td>\n",
              "      <td>Where?</td>\n",
              "      <td>Pakistan</td>\n",
              "      <td>CNN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6048</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- A high-speed car accident in Florida ...</td>\n",
              "      <td>Who was involved?</td>\n",
              "      <td>son of Hulk Hogan</td>\n",
              "      <td>Josiah Hernandez</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3792</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Louisiana is a state located in the Southern U...</td>\n",
              "      <td>And birds?</td>\n",
              "      <td>ibis and egrets</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3496</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Aragon ( or , Spanish and , or ) is an autonom...</td>\n",
              "      <td>What is the population of Aragon?</td>\n",
              "      <td>1,317,847</td>\n",
              "      <td>1,317</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3497</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Aragon ( or , Spanish and , or ) is an autonom...</td>\n",
              "      <td>Is the population widespread?</td>\n",
              "      <td>Not really</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3498</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Aragon ( or , Spanish and , or ) is an autonom...</td>\n",
              "      <td>What is the capital city?</td>\n",
              "      <td>Zaragoza</td>\n",
              "      <td>Saceza</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3500</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Aragon ( or , Spanish and , or ) is an autonom...</td>\n",
              "      <td>Does Aragon generate a lot of income?</td>\n",
              "      <td>not in the big picture</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XXII Northward, along the leeward coas...</td>\n",
              "      <td>What worked her way northward?</td>\n",
              "      <td>The _Ariel_</td>\n",
              "      <td>An angel</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3977</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER III. A RAFT. Forester and Marco did no...</td>\n",
              "      <td>Was Forester feeling ill</td>\n",
              "      <td>Yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3975</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER III. A RAFT. Forester and Marco did no...</td>\n",
              "      <td>Did Marco eat?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3973</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER III. A RAFT. Forester and Marco did no...</td>\n",
              "      <td>Who told them about the tavern</td>\n",
              "      <td>a fellow passenger</td>\n",
              "      <td>a messenger</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3972</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER III. A RAFT. Forester and Marco did no...</td>\n",
              "      <td>Who wanted to go there first</td>\n",
              "      <td>Forester</td>\n",
              "      <td>Fernando</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16de5dd8-a719-40e4-af29-e7cb464314dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16de5dd8-a719-40e4-af29-e7cb464314dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16de5dd8-a719-40e4-af29-e7cb464314dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         source                                              story  \\\n",
              "7931     mctest  The kitchen comes alive at night in the Sander...   \n",
              "4025     mctest  One morning, Justin woke up very excited. He w...   \n",
              "6653     mctest  A man sailed out to sea in a small boat. The s...   \n",
              "6652     mctest  A man sailed out to sea in a small boat. The s...   \n",
              "4029     mctest  John was in the third grade, and nine years ol...   \n",
              "23         race  My doorbell rings. On the step, I find the eld...   \n",
              "5897       race  My name is James Brown. I have an 8-year-old d...   \n",
              "3165       race  \"Everything happens for the best,\" my mother s...   \n",
              "5896       race  My name is James Brown. I have an 8-year-old d...   \n",
              "3167       race  \"Everything happens for the best,\" my mother s...   \n",
              "4140        cnn  Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...   \n",
              "3036        cnn  (CNN) -- Justin Bieber's newest friend is Mala...   \n",
              "3037        cnn  (CNN) -- Justin Bieber's newest friend is Mala...   \n",
              "3038        cnn  (CNN) -- Justin Bieber's newest friend is Mala...   \n",
              "6048        cnn  (CNN) -- A high-speed car accident in Florida ...   \n",
              "3792  wikipedia  Louisiana is a state located in the Southern U...   \n",
              "3496  wikipedia  Aragon ( or , Spanish and , or ) is an autonom...   \n",
              "3497  wikipedia  Aragon ( or , Spanish and , or ) is an autonom...   \n",
              "3498  wikipedia  Aragon ( or , Spanish and , or ) is an autonom...   \n",
              "3500  wikipedia  Aragon ( or , Spanish and , or ) is an autonom...   \n",
              "210   gutenberg  CHAPTER XXII Northward, along the leeward coas...   \n",
              "3977  gutenberg  CHAPTER III. A RAFT. Forester and Marco did no...   \n",
              "3975  gutenberg  CHAPTER III. A RAFT. Forester and Marco did no...   \n",
              "3973  gutenberg  CHAPTER III. A RAFT. Forester and Marco did no...   \n",
              "3972  gutenberg  CHAPTER III. A RAFT. Forester and Marco did no...   \n",
              "\n",
              "                                        question  \\\n",
              "7931  What do they all do when the kids come in?   \n",
              "4025                     did he go to sleep sad?   \n",
              "6653                Did he fish for a long time?   \n",
              "6652                          Did he get a bite?   \n",
              "4029                        Did he tell on them?   \n",
              "23                           Who is at the door?   \n",
              "5897                       how old is the girl ?   \n",
              "3165                    What did the father say?   \n",
              "5896                              and her dads ?   \n",
              "3167                         Did he get the job?   \n",
              "4140      What does John Howard think of Abbott?   \n",
              "3036                             How old is she?   \n",
              "3037                    Why did they attack her?   \n",
              "3038                                      Where?   \n",
              "6048                           Who was involved?   \n",
              "3792                                  And birds?   \n",
              "3496           What is the population of Aragon?   \n",
              "3497               Is the population widespread?   \n",
              "3498                   What is the capital city?   \n",
              "3500       Does Aragon generate a lot of income?   \n",
              "210               What worked her way northward?   \n",
              "3977                    Was Forester feeling ill   \n",
              "3975                              Did Marco eat?   \n",
              "3973              Who told them about the tavern   \n",
              "3972                Who wanted to go there first   \n",
              "\n",
              "                                                 answer  \\\n",
              "7931                                      they all hide   \n",
              "4025                                                 no   \n",
              "6653                                                yes   \n",
              "6652                                                 no   \n",
              "4029                                                 no   \n",
              "23             An elderly Chinese lady and a little boy   \n",
              "5897                                                 17   \n",
              "3165                Montgomery Ward wanted a sports-man   \n",
              "5896                                              Bomba   \n",
              "3167                                                 no   \n",
              "4140  understood that you could make a new friend wi...   \n",
              "3036                                                 17   \n",
              "3037             outspoken support for girls' education   \n",
              "3038                                           Pakistan   \n",
              "6048                                  son of Hulk Hogan   \n",
              "3792                                    ibis and egrets   \n",
              "3496                                          1,317,847   \n",
              "3497                                         Not really   \n",
              "3498                                           Zaragoza   \n",
              "3500                             not in the big picture   \n",
              "210                                         The _Ariel_   \n",
              "3977                                                Yes   \n",
              "3975                                                Yes   \n",
              "3973                                 a fellow passenger   \n",
              "3972                                           Forester   \n",
              "\n",
              "                           pred_answer  SQUAD_F1  \n",
              "7931                    go to the park       0.0  \n",
              "4025                               yes       0.0  \n",
              "6653                                no       0.0  \n",
              "6652                               yes       0.0  \n",
              "4029                               yes       0.0  \n",
              "23                        her daughter       0.0  \n",
              "5897                             Eight       0.0  \n",
              "3165  \"I don't want to play football.\"       0.0  \n",
              "5896                                No       0.0  \n",
              "3167                               yes       0.0  \n",
              "4140              he's a pro-socialist       0.0  \n",
              "3036                                20       0.0  \n",
              "3037              She was assassinated       0.0  \n",
              "3038                               CNN       0.0  \n",
              "6048                  Josiah Hernandez       0.0  \n",
              "3792                               yes       0.0  \n",
              "3496                             1,317       0.0  \n",
              "3497                                no       0.0  \n",
              "3498                            Saceza       0.0  \n",
              "3500                               yes       0.0  \n",
              "210                           An angel       0.0  \n",
              "3977                                no       0.0  \n",
              "3975                                no       0.0  \n",
              "3973                       a messenger       0.0  \n",
              "3972                          Fernando       0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "compute_and_display_worst(model, distilroberta_tokenizer, df_test.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zOLQRQMy6Upj",
      "metadata": {
        "id": "zOLQRQMy6Upj"
      },
      "source": [
        "### DistilRoBERTa with history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_J0w-FHt6Ehb",
      "metadata": {
        "id": "_J0w-FHt6Ehb"
      },
      "outputs": [],
      "source": [
        "# distilroberta with history\n",
        "model = EncoderDecoderModel.from_pretrained(output_paths[3]  + str(seed)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BFYGxtbdXBs8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "BFYGxtbdXBs8",
        "outputId": "1e6d09dd-1833-49ce-a9fe-eba38b566436"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2b9f8d83-bf5f-4e82-820a-1fbb549bfc84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>story</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>pred_answer</th>\n",
              "      <th>SQUAD_F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>mctest</td>\n",
              "      <td>There is a large tree in a park where all the ...</td>\n",
              "      <td>Does the tree house still exist?</td>\n",
              "      <td>yes</td>\n",
              "      <td>1896</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5072</th>\n",
              "      <td>mctest</td>\n",
              "      <td>There once was an elephant named Ellie. She re...</td>\n",
              "      <td>Who did she get them from?</td>\n",
              "      <td>Ava, from her parents bag</td>\n",
              "      <td>a peanuts</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5071</th>\n",
              "      <td>mctest</td>\n",
              "      <td>There once was an elephant named Ellie. She re...</td>\n",
              "      <td>What did she want to snack on?</td>\n",
              "      <td>peanuts.</td>\n",
              "      <td>a zoo</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5070</th>\n",
              "      <td>mctest</td>\n",
              "      <td>There once was an elephant named Ellie. She re...</td>\n",
              "      <td>Where did she live?</td>\n",
              "      <td>a circus</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5069</th>\n",
              "      <td>mctest</td>\n",
              "      <td>There once was an elephant named Ellie. She re...</td>\n",
              "      <td>Did she live in a zoo?</td>\n",
              "      <td>no</td>\n",
              "      <td>Ellie</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>race</td>\n",
              "      <td>My doorbell rings. On the step, I find the eld...</td>\n",
              "      <td>Who is at the door?</td>\n",
              "      <td>An elderly Chinese lady and a little boy</td>\n",
              "      <td>her mother</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5806</th>\n",
              "      <td>race</td>\n",
              "      <td>When I was young, I went looking for gold in C...</td>\n",
              "      <td>What covered the floor?</td>\n",
              "      <td>a rug</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5805</th>\n",
              "      <td>race</td>\n",
              "      <td>When I was young, I went looking for gold in C...</td>\n",
              "      <td>Did the narrator go into the man's house?</td>\n",
              "      <td>yes</td>\n",
              "      <td>Henry</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5804</th>\n",
              "      <td>race</td>\n",
              "      <td>When I was young, I went looking for gold in C...</td>\n",
              "      <td>What are their names?</td>\n",
              "      <td>Tom and Joe</td>\n",
              "      <td>Two</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5803</th>\n",
              "      <td>race</td>\n",
              "      <td>When I was young, I went looking for gold in C...</td>\n",
              "      <td>How many?</td>\n",
              "      <td>two</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4140</th>\n",
              "      <td>cnn</td>\n",
              "      <td>Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...</td>\n",
              "      <td>What does John Howard think of Abbott?</td>\n",
              "      <td>understood that you could make a new friend wi...</td>\n",
              "      <td>\"It's the best way to do the world.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5118</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- The man labeled the most powerful vic...</td>\n",
              "      <td>How long is the movie?</td>\n",
              "      <td>two-hours</td>\n",
              "      <td>Mary</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5117</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- The man labeled the most powerful vic...</td>\n",
              "      <td>What's the name of his daughter-in-law?</td>\n",
              "      <td>Heather Poe</td>\n",
              "      <td>72</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5116</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- The man labeled the most powerful vic...</td>\n",
              "      <td>How old is he at the time of the documentary?</td>\n",
              "      <td>72</td>\n",
              "      <td>home</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5115</th>\n",
              "      <td>cnn</td>\n",
              "      <td>(CNN) -- The man labeled the most powerful vic...</td>\n",
              "      <td>Where was he?</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>a beer</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3792</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Louisiana is a state located in the Southern U...</td>\n",
              "      <td>And birds?</td>\n",
              "      <td>ibis and egrets</td>\n",
              "      <td>snow</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5132</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Plymouth (i/ˈplɪməθ/) is a city on the south c...</td>\n",
              "      <td>What does Plymouth's early history extend to?</td>\n",
              "      <td>the Bronze Age</td>\n",
              "      <td>England</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5130</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Plymouth (i/ˈplɪməθ/) is a city on the south c...</td>\n",
              "      <td>What is it located on the south coast of?</td>\n",
              "      <td>Devon</td>\n",
              "      <td>Portuguese port</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5066</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Yorkshire ( or ; abbreviated Yorks), formally ...</td>\n",
              "      <td>why is this</td>\n",
              "      <td>due to the vast stretches of unspoilt countryside</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5065</th>\n",
              "      <td>wikipedia</td>\n",
              "      <td>Yorkshire ( or ; abbreviated Yorks), formally ...</td>\n",
              "      <td>does it have some of the greenest land</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3318</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER XV. A DISOBEDIENT BROTHER Dan was his ...</td>\n",
              "      <td>What was Paddy?</td>\n",
              "      <td>cat</td>\n",
              "      <td>Dan</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4716</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER VII The Beginning of Troubles Lily, as...</td>\n",
              "      <td>Lily left her romantic partner where?</td>\n",
              "      <td>in the garden</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4715</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER VII The Beginning of Troubles Lily, as...</td>\n",
              "      <td>was it true?</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER VII The Beginning of Troubles Lily, as...</td>\n",
              "      <td>Would people claim bernard wasn't in love?</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4646</th>\n",
              "      <td>gutenberg</td>\n",
              "      <td>CHAPTER II THE APARTMENT-HOUSE MYSTERY 1. \"Thi...</td>\n",
              "      <td>Are there many men who want to marry Ella?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>the age of the day</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b9f8d83-bf5f-4e82-820a-1fbb549bfc84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b9f8d83-bf5f-4e82-820a-1fbb549bfc84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b9f8d83-bf5f-4e82-820a-1fbb549bfc84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         source                                              story  \\\n",
              "4197     mctest  There is a large tree in a park where all the ...   \n",
              "5072     mctest  There once was an elephant named Ellie. She re...   \n",
              "5071     mctest  There once was an elephant named Ellie. She re...   \n",
              "5070     mctest  There once was an elephant named Ellie. She re...   \n",
              "5069     mctest  There once was an elephant named Ellie. She re...   \n",
              "23         race  My doorbell rings. On the step, I find the eld...   \n",
              "5806       race  When I was young, I went looking for gold in C...   \n",
              "5805       race  When I was young, I went looking for gold in C...   \n",
              "5804       race  When I was young, I went looking for gold in C...   \n",
              "5803       race  When I was young, I went looking for gold in C...   \n",
              "4140        cnn  Sydney (CNN) -- Kevin Rudd and Tony Abbott, th...   \n",
              "5118        cnn  (CNN) -- The man labeled the most powerful vic...   \n",
              "5117        cnn  (CNN) -- The man labeled the most powerful vic...   \n",
              "5116        cnn  (CNN) -- The man labeled the most powerful vic...   \n",
              "5115        cnn  (CNN) -- The man labeled the most powerful vic...   \n",
              "3792  wikipedia  Louisiana is a state located in the Southern U...   \n",
              "5132  wikipedia  Plymouth (i/ˈplɪməθ/) is a city on the south c...   \n",
              "5130  wikipedia  Plymouth (i/ˈplɪməθ/) is a city on the south c...   \n",
              "5066  wikipedia  Yorkshire ( or ; abbreviated Yorks), formally ...   \n",
              "5065  wikipedia  Yorkshire ( or ; abbreviated Yorks), formally ...   \n",
              "3318  gutenberg  CHAPTER XV. A DISOBEDIENT BROTHER Dan was his ...   \n",
              "4716  gutenberg  CHAPTER VII The Beginning of Troubles Lily, as...   \n",
              "4715  gutenberg  CHAPTER VII The Beginning of Troubles Lily, as...   \n",
              "4714  gutenberg  CHAPTER VII The Beginning of Troubles Lily, as...   \n",
              "4646  gutenberg  CHAPTER II THE APARTMENT-HOUSE MYSTERY 1. \"Thi...   \n",
              "\n",
              "                                           question  \\\n",
              "4197               Does the tree house still exist?   \n",
              "5072                     Who did she get them from?   \n",
              "5071                 What did she want to snack on?   \n",
              "5070                            Where did she live?   \n",
              "5069                         Did she live in a zoo?   \n",
              "23                              Who is at the door?   \n",
              "5806                        What covered the floor?   \n",
              "5805      Did the narrator go into the man's house?   \n",
              "5804                          What are their names?   \n",
              "5803                                      How many?   \n",
              "4140         What does John Howard think of Abbott?   \n",
              "5118                         How long is the movie?   \n",
              "5117        What's the name of his daughter-in-law?   \n",
              "5116  How old is he at the time of the documentary?   \n",
              "5115                                  Where was he?   \n",
              "3792                                     And birds?   \n",
              "5132  What does Plymouth's early history extend to?   \n",
              "5130      What is it located on the south coast of?   \n",
              "5066                                    why is this   \n",
              "5065         does it have some of the greenest land   \n",
              "3318                                What was Paddy?   \n",
              "4716          Lily left her romantic partner where?   \n",
              "4715                                   was it true?   \n",
              "4714     Would people claim bernard wasn't in love?   \n",
              "4646     Are there many men who want to marry Ella?   \n",
              "\n",
              "                                                 answer  \\\n",
              "4197                                                yes   \n",
              "5072                          Ava, from her parents bag   \n",
              "5071                                           peanuts.   \n",
              "5070                                           a circus   \n",
              "5069                                                 no   \n",
              "23             An elderly Chinese lady and a little boy   \n",
              "5806                                              a rug   \n",
              "5805                                                yes   \n",
              "5804                                        Tom and Joe   \n",
              "5803                                                two   \n",
              "4140  understood that you could make a new friend wi...   \n",
              "5118                                          two-hours   \n",
              "5117                                        Heather Poe   \n",
              "5116                                                 72   \n",
              "5115                                            Wyoming   \n",
              "3792                                    ibis and egrets   \n",
              "5132                                     the Bronze Age   \n",
              "5130                                              Devon   \n",
              "5066  due to the vast stretches of unspoilt countryside   \n",
              "5065                                                yes   \n",
              "3318                                                cat   \n",
              "4716                                      in the garden   \n",
              "4715                                                 no   \n",
              "4714                                                yes   \n",
              "4646                                                Yes   \n",
              "\n",
              "                              pred_answer  SQUAD_F1  \n",
              "4197                                 1896       0.0  \n",
              "5072                            a peanuts       0.0  \n",
              "5071                                a zoo       0.0  \n",
              "5070                                  yes       0.0  \n",
              "5069                                Ellie       0.0  \n",
              "23                             her mother       0.0  \n",
              "5806                                  yes       0.0  \n",
              "5805                                Henry       0.0  \n",
              "5804                                  Two       0.0  \n",
              "5803                                  yes       0.0  \n",
              "4140  \"It's the best way to do the world.       0.0  \n",
              "5118                                 Mary       0.0  \n",
              "5117                                   72       0.0  \n",
              "5116                                 home       0.0  \n",
              "5115                               a beer       0.0  \n",
              "3792                                 snow       0.0  \n",
              "5132                              England       0.0  \n",
              "5130                      Portuguese port       0.0  \n",
              "5066                                  yes       0.0  \n",
              "5065                                   no       0.0  \n",
              "3318                                  Dan       0.0  \n",
              "4716                                   no       0.0  \n",
              "4715                                  yes       0.0  \n",
              "4714                                   no       0.0  \n",
              "4646                   the age of the day       0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "compute_and_display_worst(model, distilroberta_tokenizer, df_test.copy(), hist = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y64aUxvMZYIe",
      "metadata": {
        "id": "Y64aUxvMZYIe"
      },
      "source": [
        "### Final considerations\n",
        "\n",
        "As it can be seen from the results obtained by the models, in both tasks DistilRoBERTa has a much better performance with respect to BERT-tiny, \n",
        "achieving a final mean SQuAD F1 score of 36.65. Moreover, it appears that no improvements are gained by taking conversational Q&A history into account. However, further experiments should be\n",
        "performed by fine-tuning the models for more than\n",
        "three epochs, to determine whether incorporating\n",
        "the history into the input can result in improved\n",
        "model performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}